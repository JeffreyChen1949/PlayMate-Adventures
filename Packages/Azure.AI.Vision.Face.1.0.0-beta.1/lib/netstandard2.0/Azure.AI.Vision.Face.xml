<?xml version="1.0" encoding="utf-8"?>
<doc>
    <assembly>
        <name>Azure.AI.Vision.Face</name>
    </assembly>
    <members>
        <member name="T:Azure.AI.Vision.Face.FaceAttributeType">
            <summary> Available options for detect face with attribute. </summary>
            <summary> Available options for detect face with attribute. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceAttributeType.Detection01">
            <summary> Available attributes for detection01 model. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.HeadPose">
            <summary> 3-D roll/yaw/pitch angles for face direction. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Glasses">
            <summary> Glasses type. Values include 'NoGlasses', 'ReadingGlasses', 'Sunglasses', 'SwimmingGoggles'. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Occlusion">
            <summary> Whether each facial area is occluded, including forehead, eyes and mouth. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Accessories">
            <summary> Accessories around face, including 'headwear', 'glasses' and 'mask'. Empty array means no accessories detected. Note this is after a face is detected. Large mask could result in no face to be detected. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Blur">
            <summary> Face is blurry or not. Level returns 'Low', 'Medium' or 'High'. Value returns a number between [0,1], the larger the blurrier. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Exposure">
            <summary> Face exposure level. Level returns 'GoodExposure', 'OverExposure' or 'UnderExposure'. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Noise">
            <summary> Noise level of face pixels. Level returns 'Low', 'Medium' and 'High'. Value returns a number between [0,1], the larger the noisier. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection01.Mask">
            <summary> Whether each face is wearing a mask. Mask type returns 'noMask', 'faceMask', 'otherMaskOrOcclusion', or 'uncertain'. Value returns a boolean 'noseAndMouthCovered' indicating whether nose and mouth are covered. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceAttributeType.Detection03">
            <summary> Available attributes for detection03 model. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection03.HeadPose">
            <summary> 3-D roll/yaw/pitch angles for face direction. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection03.Mask">
            <summary> Whether each face is wearing a mask. Mask type returns 'noMask', 'faceMask', 'otherMaskOrOcclusion', or 'uncertain'. Value returns a boolean 'noseAndMouthCovered' indicating whether nose and mouth are covered. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Detection03.Blur">
            <summary> Face is blurry or not. Level returns 'Low', 'Medium' or 'High'. Value returns a number between [0,1], the larger the blurrier. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceAttributeType.Recognition03">
            <summary> Available attributes for recognition03 model. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Recognition03.QualityForRecognition">
            <summary> The overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. The value is an informal rating of low, medium, or high. Only 'high' quality images are recommended for person enrollment and quality at or above 'medium' is recommended for identification scenarios. The attribute is only available when using any combinations of detection models detection_01 or detection_03, and recognition models recognition_03 or recognition_04. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceAttributeType.Recognition04">
            <summary> Available attributes for recognition04 model. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Recognition04.QualityForRecognition">
            <summary> The overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. The value is an informal rating of low, medium, or high. Only 'high' quality images are recommended for person enrollment and quality at or above 'medium' is recommended for identification scenarios. The attribute is only available when using any combinations of detection models detection_01 or detection_03, and recognition models recognition_03 or recognition_04. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceAttributeType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.HeadPose">
            <summary> 3-D roll/yaw/pitch angles for face direction. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Glasses">
            <summary> Glasses type. Values include 'NoGlasses', 'ReadingGlasses', 'Sunglasses', 'SwimmingGoggles'. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Occlusion">
            <summary> Whether each facial area is occluded, including forehead, eyes and mouth. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Accessories">
            <summary> Accessories around face, including 'headwear', 'glasses' and 'mask'. Empty array means no accessories detected. Note this is after a face is detected. Large mask could result in no face to be detected. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Blur">
            <summary> Face is blurry or not. Level returns 'Low', 'Medium' or 'High'. Value returns a number between [0,1], the larger the blurrier. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Exposure">
            <summary> Face exposure level. Level returns 'GoodExposure', 'OverExposure' or 'UnderExposure'. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Noise">
            <summary> Noise level of face pixels. Level returns 'Low', 'Medium' and 'High'. Value returns a number between [0,1], the larger the noisier. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Mask">
            <summary> Whether each face is wearing a mask. Mask type returns 'noMask', 'faceMask', 'otherMaskOrOcclusion', or 'uncertain'. Value returns a boolean 'noseAndMouthCovered' indicating whether nose and mouth are covered. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.QualityForRecognition">
            <summary> The overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. The value is an informal rating of low, medium, or high. Only 'high' quality images are recommended for person enrollment and quality at or above 'medium' is recommended for identification scenarios. The attribute is only available when using recognition models recognition_03 or recognition_04. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Age">
            <summary> Age in years. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Smile">
            <summary> Smile intensity, a number between [0,1]. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.FacialHair">
            <summary> Properties describing facial hair attributes. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributeType.Hair">
            <summary> Properties describing hair attributes. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.op_Equality(Azure.AI.Vision.Face.FaceAttributeType,Azure.AI.Vision.Face.FaceAttributeType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceAttributeType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.op_Inequality(Azure.AI.Vision.Face.FaceAttributeType,Azure.AI.Vision.Face.FaceAttributeType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceAttributeType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.op_Implicit(System.String)~Azure.AI.Vision.Face.FaceAttributeType">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FaceAttributeType" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.Equals(Azure.AI.Vision.Face.FaceAttributeType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributeType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceClient">
            <summary> The Face service client. </summary>
            <summary> The Face service client. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectAsync(System.Uri,Azure.AI.Vision.Face.FaceDetectionModel,Azure.AI.Vision.Face.FaceRecognitionModel,System.Boolean,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="url"> URL of input image. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="url" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.Detect(System.Uri,Azure.AI.Vision.Face.FaceDetectionModel,Azure.AI.Vision.Face.FaceRecognitionModel,System.Boolean,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="url"> URL of input image. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="url" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectAsync(System.BinaryData,Azure.AI.Vision.Face.FaceDetectionModel,Azure.AI.Vision.Face.FaceRecognitionModel,System.Boolean,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="imageContent"> The input image binary. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="imageContent" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.Detect(System.BinaryData,Azure.AI.Vision.Face.FaceDetectionModel,Azure.AI.Vision.Face.FaceRecognitionModel,System.Boolean,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="imageContent"> The input image binary. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="imageContent" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask and headPose only) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceClient.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceClient.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.#ctor">
            <summary> Initializes a new instance of FaceClient for mocking. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.#ctor(System.Uri,Azure.AzureKeyCredential)">
            <summary> Initializes a new instance of FaceClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.#ctor(System.Uri,Azure.Core.TokenCredential)">
            <summary> Initializes a new instance of FaceClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.#ctor(System.Uri,Azure.AzureKeyCredential,Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions)">
            <summary> Initializes a new instance of FaceClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.#ctor(System.Uri,Azure.Core.TokenCredential,Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions)">
            <summary> Initializes a new instance of FaceClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectFromUrlImplAsync(System.Uri,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="uri"> URL of input image. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="uri" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectFromUrlImpl(System.Uri,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="uri"> URL of input image. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="uri" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectFromUrlImplAsync(Azure.Core.RequestContent,System.String,System.String,System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.DetectFromUrlImplAsync(System.Uri,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
            <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
            <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
            <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
            <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
            <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
            <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectFromUrlImpl(Azure.Core.RequestContent,System.String,System.String,System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.DetectFromUrlImpl(System.Uri,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
            <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
            <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
            <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
            <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
            <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
            <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectImplAsync(System.BinaryData,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="imageContent"> The input image binary. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="imageContent" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectImpl(System.BinaryData,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes. </summary>
             <param name="imageContent"> The input image binary. </param>
             <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. </param>
             <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. </param>
             <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
             <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
             <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
             <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
             <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="imageContent" /> is null. </exception>
             <remarks>
             &gt; [!IMPORTANT]
             &gt; To mitigate potential misuse that can subject people to stereotyping, discrimination, or unfair denial of services, we are retiring Face API attributes that predict emotion, gender, age, smile, facial hair, hair, and makeup. Read more about this decision https://azure.microsoft.com/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/.
            
             *
               * No image will be stored. Only the extracted face feature(s) will be stored on server. The faceId is an identifier of the face feature and will be used in "Identify", "Verify", and "Find Similar". The stored face features will expire and be deleted at the time specified by faceIdTimeToLive after the original detection call.
               * Optional parameters include faceId, landmarks, and attributes. Attributes include headPose, glasses, occlusion, accessories, blur, exposure, noise, mask, and qualityForRecognition. Some of the results returned for specific attributes may not be highly accurate.
               * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.
               * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum face size.
               * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from large to small.
               * For optimal results when querying "Identify", "Verify", and "Find Similar" ('returnFaceId' is true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels (100 pixels between eyes).
               * Different 'detectionModel' values can be provided. To use and compare different detection models, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-detection-model
                 * 'detection_02': Face attributes and landmarks are disabled if you choose this detection model.
                 * 'detection_03': Face attributes (mask, blur, and headPose) and landmarks are supported if you choose this detection model.
               * Different 'recognitionModel' values are provided. If follow-up operations like "Verify", "Identify", "Find Similar" are needed, please specify the recognition model with 'recognitionModel' parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model needed, please explicitly specify the model you need in this parameter. Once specified, the detected faceIds will be associated with the specified recognition model. More details, please refer to https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/specify-recognition-model.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectImplAsync(Azure.Core.RequestContent,System.String,System.String,System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.DetectImplAsync(System.BinaryData,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
            <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
            <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
            <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
            <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
            <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
            <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.DetectImpl(Azure.Core.RequestContent,System.String,System.String,System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.DetectImpl(System.BinaryData,System.Nullable{Azure.AI.Vision.Face.FaceDetectionModel},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},System.Nullable{System.Boolean},System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.FaceAttributeType},System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="detectionModel"> The 'detectionModel' associated with the detected faceIds. Supported 'detectionModel' values include 'detection_01', 'detection_02' and 'detection_03'. The default value is 'detection_01'. Allowed values: "detection_01" | "detection_02" | "detection_03". </param>
            <param name="recognitionModel"> The 'recognitionModel' associated with the detected faceIds. Supported 'recognitionModel' values include 'recognition_01', 'recognition_02', 'recognition_03' or 'recognition_04'. The default value is 'recognition_01'. 'recognition_04' is recommended since its accuracy is improved on faces wearing masks compared with 'recognition_03', and its overall accuracy is improved compared with 'recognition_01' and 'recognition_02'. Allowed values: "recognition_01" | "recognition_02" | "recognition_03" | "recognition_04". </param>
            <param name="returnFaceId"> Return faceIds of the detected faces or not. The default value is true. </param>
            <param name="returnFaceAttributes"> Analyze and return the one or more specified face attributes in the comma-separated string like 'returnFaceAttributes=headPose,glasses'. Face attribute analysis has additional computational and time cost. </param>
            <param name="returnFaceLandmarks"> Return face landmarks of the detected faces or not. The default value is false. </param>
            <param name="returnRecognitionModel"> Return 'recognitionModel' or not. The default value is false. This is only applicable when returnFaceId = true. </param>
            <param name="faceIdTimeToLive"> The number of seconds for the face ID being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.FindSimilarAsync(System.Guid,System.Collections.Generic.IEnumerable{System.Guid},System.Nullable{System.Int32},System.Nullable{Azure.AI.Vision.Face.FindSimilarMatchMode},System.Threading.CancellationToken)">
             <summary> Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. </summary>
             <param name="faceId"> faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
             <param name="faceIds"> An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
             <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000]. Default value is 20. </param>
             <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. Default value is 'matchPerson'. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="faceIds" /> is null. </exception>
             <remarks>
             Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
            
             Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
            
             The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the target faceId array.
             </remarks>
             <example>
This sample shows how to call FindSimilarAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<IReadOnlyList<FaceFindSimilarResult>> response = await client.FindSimilarAsync(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") });
]]></code>
This sample shows how to call FindSimilarAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<IReadOnlyList<FaceFindSimilarResult>> response = await client.FindSimilarAsync(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") }, maxNumOfCandidatesReturned: 1234, mode: FindSimilarMatchMode.MatchPerson);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.FindSimilar(System.Guid,System.Collections.Generic.IEnumerable{System.Guid},System.Nullable{System.Int32},System.Nullable{Azure.AI.Vision.Face.FindSimilarMatchMode},System.Threading.CancellationToken)">
             <summary> Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect. </summary>
             <param name="faceId"> faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
             <param name="faceIds"> An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
             <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000]. Default value is 20. </param>
             <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. Default value is 'matchPerson'. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="faceIds" /> is null. </exception>
             <remarks>
             Depending on the input the returned similar faces list contains faceIds or persistedFaceIds ranked by similarity.
            
             Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson" is the default mode that it tries to find faces of the same person as possible by using internal same-person thresholds. It is useful to find a known person's other photos. Note that an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is low. It can be used in the cases like searching celebrity-looking faces.
            
             The 'recognitionModel' associated with the query faceId should be the same as the 'recognitionModel' used by the target faceId array.
             </remarks>
             <example>
This sample shows how to call FindSimilar.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<IReadOnlyList<FaceFindSimilarResult>> response = client.FindSimilar(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") });
]]></code>
This sample shows how to call FindSimilar with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<IReadOnlyList<FaceFindSimilarResult>> response = client.FindSimilar(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") }, maxNumOfCandidatesReturned: 1234, mode: FindSimilarMatchMode.MatchPerson);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.FindSimilarAsync(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.FindSimilarAsync(System.Guid,System.Collections.Generic.IEnumerable{System.Guid},System.Nullable{System.Int32},System.Nullable{Azure.AI.Vision.Face.FindSimilarMatchMode},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call FindSimilarAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = await client.FindSimilarAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("confidence").ToString());
]]></code>
This sample shows how to call FindSimilarAsync with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    maxNumOfCandidatesReturned = 1234,
    mode = "matchPerson",
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = await client.FindSimilarAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("confidence").ToString());
Console.WriteLine(result[0].GetProperty("faceId").ToString());
Console.WriteLine(result[0].GetProperty("persistedFaceId").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.FindSimilar(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Given query face's faceId, to search the similar-looking faces from a faceId array. A faceId array contains the faces created by Detect.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.FindSimilar(System.Guid,System.Collections.Generic.IEnumerable{System.Guid},System.Nullable{System.Int32},System.Nullable{Azure.AI.Vision.Face.FindSimilarMatchMode},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call FindSimilar and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = client.FindSimilar(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("confidence").ToString());
]]></code>
This sample shows how to call FindSimilar with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    maxNumOfCandidatesReturned = 1234,
    mode = "matchPerson",
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = client.FindSimilar(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("confidence").ToString());
Console.WriteLine(result[0].GetProperty("faceId").ToString());
Console.WriteLine(result[0].GetProperty("persistedFaceId").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.VerifyFaceToFaceAsync(System.Guid,System.Guid,System.Threading.CancellationToken)">
            <summary> Verify whether two faces belong to a same person. </summary>
            <param name="faceId1"> The faceId of one face, come from "Detect". </param>
            <param name="faceId2"> The faceId of another face, come from "Detect". </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <remarks>
            &gt; [!NOTE]
            &gt;
            &gt; *
            &gt;   * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
            &gt;   * For the scenarios that are sensitive to accuracy please make your own judgment.
            &gt;   * The 'recognitionModel' associated with the both faces should be the same.
            </remarks>
            <example>
This sample shows how to call VerifyFaceToFaceAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceVerificationResult> response = await client.VerifyFaceToFaceAsync(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"));
]]></code>
This sample shows how to call VerifyFaceToFaceAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceVerificationResult> response = await client.VerifyFaceToFaceAsync(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"));
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.VerifyFaceToFace(System.Guid,System.Guid,System.Threading.CancellationToken)">
            <summary> Verify whether two faces belong to a same person. </summary>
            <param name="faceId1"> The faceId of one face, come from "Detect". </param>
            <param name="faceId2"> The faceId of another face, come from "Detect". </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <remarks>
            &gt; [!NOTE]
            &gt;
            &gt; *
            &gt;   * Higher face image quality means better identification precision. Please consider high-quality faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
            &gt;   * For the scenarios that are sensitive to accuracy please make your own judgment.
            &gt;   * The 'recognitionModel' associated with the both faces should be the same.
            </remarks>
            <example>
This sample shows how to call VerifyFaceToFace.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceVerificationResult> response = client.VerifyFaceToFace(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"));
]]></code>
This sample shows how to call VerifyFaceToFace with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceVerificationResult> response = client.VerifyFaceToFace(Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"), Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"));
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.VerifyFaceToFaceAsync(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Verify whether two faces belong to a same person.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.VerifyFaceToFaceAsync(System.Guid,System.Guid,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call VerifyFaceToFaceAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId1 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    faceId2 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
});
Response response = await client.VerifyFaceToFaceAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("confidence").ToString());
]]></code>
This sample shows how to call VerifyFaceToFaceAsync with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId1 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    faceId2 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
});
Response response = await client.VerifyFaceToFaceAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("confidence").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.VerifyFaceToFace(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Verify whether two faces belong to a same person.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.VerifyFaceToFace(System.Guid,System.Guid,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call VerifyFaceToFace and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId1 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    faceId2 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
});
Response response = client.VerifyFaceToFace(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("confidence").ToString());
]]></code>
This sample shows how to call VerifyFaceToFace with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceId1 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
    faceId2 = "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a",
});
Response response = client.VerifyFaceToFace(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("confidence").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.GroupAsync(System.Collections.Generic.IEnumerable{System.Guid},System.Threading.CancellationToken)">
            <summary> Divide candidate faces into groups based on face similarity. </summary>
            <param name="faceIds"> Array of candidate faceIds created by "Detect". The maximum is 1000 faces. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceIds" /> is null. </exception>
            <remarks>
            &gt;
            *
              * The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result.
              * MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts.
              * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try "Verify Face To Face" when you only have 2 candidate faces.
              * The 'recognitionModel' associated with the query faces' faceIds should be the same.
            </remarks>
            <example>
This sample shows how to call GroupAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceGroupingResult> response = await client.GroupAsync(new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") });
]]></code>
This sample shows how to call GroupAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceGroupingResult> response = await client.GroupAsync(new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") });
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.Group(System.Collections.Generic.IEnumerable{System.Guid},System.Threading.CancellationToken)">
            <summary> Divide candidate faces into groups based on face similarity. </summary>
            <param name="faceIds"> Array of candidate faceIds created by "Detect". The maximum is 1000 faces. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceIds" /> is null. </exception>
            <remarks>
            &gt;
            *
              * The output is one or more disjointed face groups and a messyGroup. A face group contains faces that have similar looking, often of the same person. Face groups are ranked by group size, i.e. number of faces. Notice that faces belonging to a same person might be split into several groups in the result.
              * MessyGroup is a special face group containing faces that cannot find any similar counterpart face from original faces. The messyGroup will not appear in the result if all faces found their counterparts.
              * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try "Verify Face To Face" when you only have 2 candidate faces.
              * The 'recognitionModel' associated with the query faces' faceIds should be the same.
            </remarks>
            <example>
This sample shows how to call Group.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceGroupingResult> response = client.Group(new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") });
]]></code>
This sample shows how to call Group with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

Response<FaceGroupingResult> response = client.Group(new Guid[] { Guid.Parse("73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a") });
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.GroupAsync(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Divide candidate faces into groups based on face similarity.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.GroupAsync(System.Collections.Generic.IEnumerable{System.Guid},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GroupAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = await client.GroupAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("groups")[0][0].ToString());
Console.WriteLine(result.GetProperty("messyGroup")[0].ToString());
]]></code>
This sample shows how to call GroupAsync with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = await client.GroupAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("groups")[0][0].ToString());
Console.WriteLine(result.GetProperty("messyGroup")[0].ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceClient.Group(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Divide candidate faces into groups based on face similarity.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceClient.Group(System.Collections.Generic.IEnumerable{System.Guid},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call Group and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = client.Group(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("groups")[0][0].ToString());
Console.WriteLine(result.GetProperty("messyGroup")[0].ToString());
]]></code>
This sample shows how to call Group with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceClient client = new FaceClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    faceIds = new object[]
    {
        "73f411fe-4f43-4b4b-9cbd-6828d8f4cf9a"
    },
});
Response response = client.Group(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("groups")[0][0].ToString());
Console.WriteLine(result.GetProperty("messyGroup")[0].ToString());
]]></code></example>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceSessionClient">
            <summary> The FaceSession service client. </summary>
            <summary> The FaceSession service client. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionAsync(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.IO.Stream,System.Threading.CancellationToken)">
             <summary> Create a new liveness session with verify. Provide the verify image during session creation. </summary>
             <param name="createLivenessSessionContent"> Parameters for liveness with verify session creation. </param>
             <param name="verifyImage"> Image binary data for verify image, can be provided as session creation time or during the /detectLivenessWithVerify/singleModal  </param>///
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessSessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLivenessWithVerify/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt;
             &gt; *
             &gt;   * Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation.
             &gt;   * To retrieve a result, use the Get Liveness With Verify Session.
             &gt;   * To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.
            
             Recommended Option: VerifyImage is provided during session creation.
             Alternative Option: Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.
             &gt; [!NOTE]
             &gt; Extra measures should be taken to validate that the client is sending the expected VerifyImage.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySession(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.IO.Stream,System.Threading.CancellationToken)">
             <summary> Create a new liveness session with verify. Provide the verify image during session creation. </summary>
             <param name="createLivenessSessionContent"> Parameters for liveness with verify session creation. </param>
             <param name="verifyImage"> Image binary data for verify image, can be provided as session creation time or during the /detectLivenessWithVerify/singleModal  </param>///
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessSessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLivenessWithVerify/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt;
             &gt; *
             &gt;   * Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation.
             &gt;   * To retrieve a result, use the Get Liveness With Verify Session.
             &gt;   * To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.
            
             Recommended Option: VerifyImage is provided during session creation.
             Alternative Option: Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.
             &gt; [!NOTE]
             &gt; Extra measures should be taken to validate that the client is sending the expected VerifyImage.
             </remarks>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceSessionClient.ClientDiagnostics">
            <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceSessionClient.Pipeline">
            <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.#ctor">
            <summary> Initializes a new instance of FaceSessionClient for mocking. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.#ctor(System.Uri,Azure.AzureKeyCredential)">
            <summary> Initializes a new instance of FaceSessionClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.#ctor(System.Uri,Azure.Core.TokenCredential)">
            <summary> Initializes a new instance of FaceSessionClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.#ctor(System.Uri,Azure.AzureKeyCredential,Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions)">
            <summary> Initializes a new instance of FaceSessionClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.#ctor(System.Uri,Azure.Core.TokenCredential,Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions)">
            <summary> Initializes a new instance of FaceSessionClient. </summary>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
            <param name="options"> The options for configuring the client. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="endpoint" /> or <paramref name="credential" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessSessionAsync(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)">
             <summary> Create a new detect liveness session. </summary>
             <param name="createLivenessSessionContent"> Request for creating liveness session. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessSessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLiveness/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt; Client access can be revoked by deleting the session using the Delete Liveness Session operation. To retrieve a result, use the Get Liveness Session. To audit the individual requests that a client has made to your resource, use the List Liveness Session Audit Entries.
             </remarks>
             <example>
This sample shows how to call CreateLivenessSessionAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

CreateLivenessSessionContent createLivenessSessionContent = new CreateLivenessSessionContent(LivenessOperationMode.Passive);
Response<CreateLivenessSessionResult> response = await client.CreateLivenessSessionAsync(createLivenessSessionContent);
]]></code>
This sample shows how to call CreateLivenessSessionAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

CreateLivenessSessionContent createLivenessSessionContent = new CreateLivenessSessionContent(LivenessOperationMode.Passive)
{
    SendResultsToClient = true,
    DeviceCorrelationIdSetInClient = true,
    DeviceCorrelationId = "<deviceCorrelationId>",
    AuthTokenTimeToLiveInSeconds = 1234,
};
Response<CreateLivenessSessionResult> response = await client.CreateLivenessSessionAsync(createLivenessSessionContent);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessSession(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)">
             <summary> Create a new detect liveness session. </summary>
             <param name="createLivenessSessionContent"> Request for creating liveness session. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessSessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLiveness/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt; Client access can be revoked by deleting the session using the Delete Liveness Session operation. To retrieve a result, use the Get Liveness Session. To audit the individual requests that a client has made to your resource, use the List Liveness Session Audit Entries.
             </remarks>
             <example>
This sample shows how to call CreateLivenessSession.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

CreateLivenessSessionContent createLivenessSessionContent = new CreateLivenessSessionContent(LivenessOperationMode.Passive);
Response<CreateLivenessSessionResult> response = client.CreateLivenessSession(createLivenessSessionContent);
]]></code>
This sample shows how to call CreateLivenessSession with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

CreateLivenessSessionContent createLivenessSessionContent = new CreateLivenessSessionContent(LivenessOperationMode.Passive)
{
    SendResultsToClient = true,
    DeviceCorrelationIdSetInClient = true,
    DeviceCorrelationId = "<deviceCorrelationId>",
    AuthTokenTimeToLiveInSeconds = 1234,
};
Response<CreateLivenessSessionResult> response = client.CreateLivenessSession(createLivenessSessionContent);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessSessionAsync(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Create a new detect liveness session.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessSessionAsync(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call CreateLivenessSessionAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    livenessOperationMode = "Passive",
});
Response response = await client.CreateLivenessSessionAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("authToken").ToString());
]]></code>
This sample shows how to call CreateLivenessSessionAsync with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    livenessOperationMode = "Passive",
    sendResultsToClient = true,
    deviceCorrelationIdSetInClient = true,
    deviceCorrelationId = "<deviceCorrelationId>",
    authTokenTimeToLiveInSeconds = 1234,
});
Response response = await client.CreateLivenessSessionAsync(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("authToken").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessSession(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Create a new detect liveness session.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessSession(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call CreateLivenessSession and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    livenessOperationMode = "Passive",
});
Response response = client.CreateLivenessSession(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("authToken").ToString());
]]></code>
This sample shows how to call CreateLivenessSession with all request content and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

using RequestContent content = RequestContent.Create(new
{
    livenessOperationMode = "Passive",
    sendResultsToClient = true,
    deviceCorrelationIdSetInClient = true,
    deviceCorrelationId = "<deviceCorrelationId>",
    authTokenTimeToLiveInSeconds = 1234,
});
Response response = client.CreateLivenessSession(content);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("authToken").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.DeleteLivenessSessionAsync(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Delete all session related information for matching the specified session id.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call DeleteLivenessSessionAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.DeleteLivenessSessionAsync("<sessionId>");

Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DeleteLivenessSessionAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.DeleteLivenessSessionAsync("<sessionId>");

Console.WriteLine(response.Status);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.DeleteLivenessSession(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Delete all session related information for matching the specified session id.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call DeleteLivenessSession.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.DeleteLivenessSession("<sessionId>");

Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DeleteLivenessSession with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.DeleteLivenessSession("<sessionId>");

Console.WriteLine(response.Status);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionResultAsync(System.String,System.Threading.CancellationToken)">
            <summary> Get session result of detectLiveness/singleModal call. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessSessionResultAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessSession> response = await client.GetLivenessSessionResultAsync("<sessionId>");
]]></code>
This sample shows how to call GetLivenessSessionResultAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessSession> response = await client.GetLivenessSessionResultAsync("<sessionId>");
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionResult(System.String,System.Threading.CancellationToken)">
            <summary> Get session result of detectLiveness/singleModal call. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessSessionResult.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessSession> response = client.GetLivenessSessionResult("<sessionId>");
]]></code>
This sample shows how to call GetLivenessSessionResult with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessSession> response = client.GetLivenessSessionResult("<sessionId>");
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionResultAsync(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Get session result of detectLiveness/singleModal call.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionResultAsync(System.String,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessSessionResultAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessSessionResultAsync("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
]]></code>
This sample shows how to call GetLivenessSessionResultAsync with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessSessionResultAsync("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result.GetProperty("authTokenTimeToLiveInSeconds").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("requestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("clientRequestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("receivedDateTime").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionResult(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Get session result of detectLiveness/singleModal call.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionResult(System.String,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessSessionResult and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessSessionResult("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
]]></code>
This sample shows how to call GetLivenessSessionResult with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessSessionResult("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result.GetProperty("authTokenTimeToLiveInSeconds").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("requestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("clientRequestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("receivedDateTime").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionsAsync(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Lists sessions for /detectLiveness/SingleModal. </summary>
             <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
             <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <remarks>
             List sessions from the last sessionId greater than the 'start'.
            
             The result should be ordered by sessionId in ascending order.
             </remarks>
             <example>
This sample shows how to call GetLivenessSessionsAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = await client.GetLivenessSessionsAsync();
]]></code>
This sample shows how to call GetLivenessSessionsAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = await client.GetLivenessSessionsAsync(start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessions(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Lists sessions for /detectLiveness/SingleModal. </summary>
             <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
             <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <remarks>
             List sessions from the last sessionId greater than the 'start'.
            
             The result should be ordered by sessionId in ascending order.
             </remarks>
             <example>
This sample shows how to call GetLivenessSessions.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = client.GetLivenessSessions();
]]></code>
This sample shows how to call GetLivenessSessions with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = client.GetLivenessSessions(start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionsAsync(System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Lists sessions for /detectLiveness/SingleModal.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionsAsync(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessSessionsAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessSessionsAsync(null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
]]></code>
This sample shows how to call GetLivenessSessionsAsync with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessSessionsAsync("<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
Console.WriteLine(result[0].GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result[0].GetProperty("authTokenTimeToLiveInSeconds").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessions(System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Lists sessions for /detectLiveness/SingleModal.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessions(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessSessions and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessSessions(null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
]]></code>
This sample shows how to call GetLivenessSessions with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessSessions("<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
Console.WriteLine(result[0].GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result[0].GetProperty("authTokenTimeToLiveInSeconds").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionAuditEntriesAsync(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary> Gets session requests and response body for the session. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessSessionAuditEntriesAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = await client.GetLivenessSessionAuditEntriesAsync("<sessionId>");
]]></code>
This sample shows how to call GetLivenessSessionAuditEntriesAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = await client.GetLivenessSessionAuditEntriesAsync("<sessionId>", start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionAuditEntries(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary> Gets session requests and response body for the session. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessSessionAuditEntries.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = client.GetLivenessSessionAuditEntries("<sessionId>");
]]></code>
This sample shows how to call GetLivenessSessionAuditEntries with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = client.GetLivenessSessionAuditEntries("<sessionId>", start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionAuditEntriesAsync(System.String,System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Gets session requests and response body for the session.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionAuditEntriesAsync(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessSessionAuditEntriesAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessSessionAuditEntriesAsync("<sessionId>", null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code>
This sample shows how to call GetLivenessSessionAuditEntriesAsync with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessSessionAuditEntriesAsync("<sessionId>", "<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionAuditEntries(System.String,System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Gets session requests and response body for the session.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessSessionAuditEntries(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessSessionAuditEntries and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessSessionAuditEntries("<sessionId>", null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code>
This sample shows how to call GetLivenessSessionAuditEntries with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessSessionAuditEntries("<sessionId>", "<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionAsync(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)">
             <summary> Create a new liveness session with verify. Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call. </summary>
             <param name="createLivenessSessionContent"> Request for creating liveness session. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessSessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLivenessWithVerify/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt;
             &gt; *
             &gt;   * Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation.
             &gt;   * To retrieve a result, use the Get Liveness With Verify Session.
             &gt;   * To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.
            
             Alternative Option: Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.
             &gt; [!NOTE]
             &gt; Extra measures should be taken to validate that the client is sending the expected VerifyImage.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySession(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)">
             <summary> Create a new liveness session with verify. Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call. </summary>
             <param name="createLivenessSessionContent"> Request for creating liveness session. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessSessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLivenessWithVerify/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt;
             &gt; *
             &gt;   * Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation.
             &gt;   * To retrieve a result, use the Get Liveness With Verify Session.
             &gt;   * To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.
            
             Alternative Option: Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.
             &gt; [!NOTE]
             &gt; Extra measures should be taken to validate that the client is sending the expected VerifyImage.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionAsync(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Create a new liveness session with verify. Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionAsync(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySession(Azure.Core.RequestContent,Azure.RequestContext)">
            <summary>
            [Protocol Method] Create a new liveness session with verify. Client device submits VerifyImage during the /detectLivenessWithVerify/singleModal call.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySession(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionWithVerifyImageAsync(Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent,System.Threading.CancellationToken)">
             <summary> Create a new liveness session with verify. Provide the verify image during session creation. </summary>
             <param name="createLivenessWithVerifySessionContent"> Request of liveness with verify session creation. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessWithVerifySessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLivenessWithVerify/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt;
             &gt; *
             &gt;   * Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation.
             &gt;   * To retrieve a result, use the Get Liveness With Verify Session.
             &gt;   * To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.
            
             Recommended Option: VerifyImage is provided during session creation.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionWithVerifyImage(Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent,System.Threading.CancellationToken)">
             <summary> Create a new liveness session with verify. Provide the verify image during session creation. </summary>
             <param name="createLivenessWithVerifySessionContent"> Request of liveness with verify session creation. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <exception cref="T:System.ArgumentNullException"> <paramref name="createLivenessWithVerifySessionContent" /> is null. </exception>
             <remarks>
             A session is best for client device scenarios where developers want to authorize a client device to perform only a liveness detection without granting full access to their resource. Created sessions have a limited life span and only authorize clients to perform the desired action before access is expired.
            
             Permissions includes...
             &gt;
             *
               * Ability to call /detectLivenessWithVerify/singleModal for up to 3 retries.
               * A token lifetime of 10 minutes.
            
             &gt; [!NOTE]
             &gt;
             &gt; *
             &gt;   * Client access can be revoked by deleting the session using the Delete Liveness With Verify Session operation.
             &gt;   * To retrieve a result, use the Get Liveness With Verify Session.
             &gt;   * To audit the individual requests that a client has made to your resource, use the List Liveness With Verify Session Audit Entries.
            
             Recommended Option: VerifyImage is provided during session creation.
             </remarks>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionWithVerifyImageAsync(Azure.Core.RequestContent,System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Create a new liveness session with verify. Provide the verify image during session creation.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionWithVerifyImageAsync(Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="contentType"> The content type for the operation. Always multipart/form-data for this operation. Allowed values: "multipart/form-data". </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionWithVerifyImage(Azure.Core.RequestContent,System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Create a new liveness session with verify. Provide the verify image during session creation.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.CreateLivenessWithVerifySessionWithVerifyImage(Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="content"> The content to send as the body of the request. </param>
            <param name="contentType"> The content type for the operation. Always multipart/form-data for this operation. Allowed values: "multipart/form-data". </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="content" /> is null. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.DeleteLivenessWithVerifySessionAsync(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Delete all session related information for matching the specified session id.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call DeleteLivenessWithVerifySessionAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.DeleteLivenessWithVerifySessionAsync("<sessionId>");

Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DeleteLivenessWithVerifySessionAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.DeleteLivenessWithVerifySessionAsync("<sessionId>");

Console.WriteLine(response.Status);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.DeleteLivenessWithVerifySession(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Delete all session related information for matching the specified session id.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call DeleteLivenessWithVerifySession.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.DeleteLivenessWithVerifySession("<sessionId>");

Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DeleteLivenessWithVerifySession with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.DeleteLivenessWithVerifySession("<sessionId>");

Console.WriteLine(response.Status);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionResultAsync(System.String,System.Threading.CancellationToken)">
            <summary> Get session result of detectLivenessWithVerify/singleModal call. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessWithVerifySessionResultAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessWithVerifySession> response = await client.GetLivenessWithVerifySessionResultAsync("<sessionId>");
]]></code>
This sample shows how to call GetLivenessWithVerifySessionResultAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessWithVerifySession> response = await client.GetLivenessWithVerifySessionResultAsync("<sessionId>");
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionResult(System.String,System.Threading.CancellationToken)">
            <summary> Get session result of detectLivenessWithVerify/singleModal call. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessWithVerifySessionResult.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessWithVerifySession> response = client.GetLivenessWithVerifySessionResult("<sessionId>");
]]></code>
This sample shows how to call GetLivenessWithVerifySessionResult with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<LivenessWithVerifySession> response = client.GetLivenessWithVerifySessionResult("<sessionId>");
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionResultAsync(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Get session result of detectLivenessWithVerify/singleModal call.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionResultAsync(System.String,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessWithVerifySessionResultAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessWithVerifySessionResultAsync("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
]]></code>
This sample shows how to call GetLivenessWithVerifySessionResultAsync with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessWithVerifySessionResultAsync("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result.GetProperty("authTokenTimeToLiveInSeconds").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("requestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("clientRequestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("receivedDateTime").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionResult(System.String,Azure.RequestContext)">
            <summary>
            [Protocol Method] Get session result of detectLivenessWithVerify/singleModal call.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionResult(System.String,System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessWithVerifySessionResult and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessWithVerifySessionResult("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
]]></code>
This sample shows how to call GetLivenessWithVerifySessionResult with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessWithVerifySessionResult("<sessionId>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("createdDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result.GetProperty("sessionExpired").ToString());
Console.WriteLine(result.GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result.GetProperty("authTokenTimeToLiveInSeconds").ToString());
Console.WriteLine(result.GetProperty("status").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("sessionId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("requestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("clientRequestId").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("receivedDateTime").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result.GetProperty("result").GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionsAsync(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Lists sessions for /detectLivenessWithVerify/SingleModal. </summary>
             <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
             <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <remarks>
             List sessions from the last sessionId greater than the "start".
            
             The result should be ordered by sessionId in ascending order.
             </remarks>
             <example>
This sample shows how to call GetLivenessWithVerifySessionsAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = await client.GetLivenessWithVerifySessionsAsync();
]]></code>
This sample shows how to call GetLivenessWithVerifySessionsAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = await client.GetLivenessWithVerifySessionsAsync(start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessions(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
             <summary> Lists sessions for /detectLivenessWithVerify/SingleModal. </summary>
             <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
             <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
             <param name="cancellationToken"> The cancellation token to use. </param>
             <remarks>
             List sessions from the last sessionId greater than the "start".
            
             The result should be ordered by sessionId in ascending order.
             </remarks>
             <example>
This sample shows how to call GetLivenessWithVerifySessions.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = client.GetLivenessWithVerifySessions();
]]></code>
This sample shows how to call GetLivenessWithVerifySessions with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionItem>> response = client.GetLivenessWithVerifySessions(start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionsAsync(System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Lists sessions for /detectLivenessWithVerify/SingleModal.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionsAsync(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessWithVerifySessionsAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessWithVerifySessionsAsync(null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
]]></code>
This sample shows how to call GetLivenessWithVerifySessionsAsync with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessWithVerifySessionsAsync("<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
Console.WriteLine(result[0].GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result[0].GetProperty("authTokenTimeToLiveInSeconds").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessions(System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Lists sessions for /detectLivenessWithVerify/SingleModal.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessions(System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessWithVerifySessions and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessWithVerifySessions(null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
]]></code>
This sample shows how to call GetLivenessWithVerifySessions with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessWithVerifySessions("<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("createdDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionStartDateTime").ToString());
Console.WriteLine(result[0].GetProperty("sessionExpired").ToString());
Console.WriteLine(result[0].GetProperty("deviceCorrelationId").ToString());
Console.WriteLine(result[0].GetProperty("authTokenTimeToLiveInSeconds").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionAuditEntriesAsync(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary> Gets session requests and response body for the session. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessWithVerifySessionAuditEntriesAsync.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = await client.GetLivenessWithVerifySessionAuditEntriesAsync("<sessionId>");
]]></code>
This sample shows how to call GetLivenessWithVerifySessionAuditEntriesAsync with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = await client.GetLivenessWithVerifySessionAuditEntriesAsync("<sessionId>", start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionAuditEntries(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)">
            <summary> Gets session requests and response body for the session. </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="cancellationToken"> The cancellation token to use. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <example>
This sample shows how to call GetLivenessWithVerifySessionAuditEntries.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = client.GetLivenessWithVerifySessionAuditEntries("<sessionId>");
]]></code>
This sample shows how to call GetLivenessWithVerifySessionAuditEntries with all parameters.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response<IReadOnlyList<LivenessSessionAuditEntry>> response = client.GetLivenessWithVerifySessionAuditEntries("<sessionId>", start: "<start>", top: 1234);
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionAuditEntriesAsync(System.String,System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Gets session requests and response body for the session.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionAuditEntriesAsync(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessWithVerifySessionAuditEntriesAsync and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessWithVerifySessionAuditEntriesAsync("<sessionId>", null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code>
This sample shows how to call GetLivenessWithVerifySessionAuditEntriesAsync with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = await client.GetLivenessWithVerifySessionAuditEntriesAsync("<sessionId>", "<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionAuditEntries(System.String,System.String,System.Nullable{System.Int32},Azure.RequestContext)">
            <summary>
            [Protocol Method] Gets session requests and response body for the session.
            <list type="bullet">
            <item>
            <description>
            This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
            </description>
            </item>
            <item>
            <description>
            Please try the simpler <see cref="M:Azure.AI.Vision.Face.FaceSessionClient.GetLivenessWithVerifySessionAuditEntries(System.String,System.String,System.Nullable{System.Int32},System.Threading.CancellationToken)" /> convenience overload with strongly typed models first.
            </description>
            </item>
            </list>
            </summary>
            <param name="sessionId"> The unique ID to reference this session. </param>
            <param name="start"> List resources greater than the "start". It contains no more than 64 characters. Default is empty. </param>
            <param name="top"> The number of items to list, ranging in [1, 1000]. Default is 1000. </param>
            <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> is null. </exception>
            <exception cref="T:System.ArgumentException"> <paramref name="sessionId" /> is an empty string, and was expected to be non-empty. </exception>
            <exception cref="T:Azure.RequestFailedException"> Service returned a non-success status code. </exception>
            <returns> The response returned from the service. </returns>
            <example>
This sample shows how to call GetLivenessWithVerifySessionAuditEntries and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessWithVerifySessionAuditEntries("<sessionId>", null, null, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code>
This sample shows how to call GetLivenessWithVerifySessionAuditEntries with all parameters and parse the result.
<code><![CDATA[
Uri endpoint = new Uri("<https://my-service.azure.com>");
AzureKeyCredential credential = new AzureKeyCredential("<key>");
FaceSessionClient client = new FaceSessionClient(endpoint, credential);

Response response = client.GetLivenessWithVerifySessionAuditEntries("<sessionId>", "<start>", 1234, null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result[0].GetProperty("id").ToString());
Console.WriteLine(result[0].GetProperty("sessionId").ToString());
Console.WriteLine(result[0].GetProperty("requestId").ToString());
Console.WriteLine(result[0].GetProperty("clientRequestId").ToString());
Console.WriteLine(result[0].GetProperty("receivedDateTime").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("url").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("method").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentLength").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("contentType").ToString());
Console.WriteLine(result[0].GetProperty("request").GetProperty("userAgent").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("livenessDecision").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("fileName").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("timeOffsetWithinFile").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("target").GetProperty("imageType").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("modelVersionUsed").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("top").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("left").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("width").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("faceRectangle").GetProperty("height").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("verifyImage").GetProperty("qualityForRecognition").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("matchConfidence").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("body").GetProperty("verifyResult").GetProperty("isIdentical").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("statusCode").ToString());
Console.WriteLine(result[0].GetProperty("response").GetProperty("latencyInMilliseconds").ToString());
Console.WriteLine(result[0].GetProperty("digest").ToString());
]]></code></example>
        </member>
        <member name="T:Azure.AI.Vision.Face.AccessoryItem">
            <summary> Accessory item and corresponding confidence level. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.#ctor(Azure.AI.Vision.Face.AccessoryType,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AccessoryItem" />. </summary>
            <param name="type"> Type of the accessory. </param>
            <param name="confidence"> Confidence level of the accessory type. Range between [0,1]. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.#ctor(Azure.AI.Vision.Face.AccessoryType,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AccessoryItem" />. </summary>
            <param name="type"> Type of the accessory. </param>
            <param name="confidence"> Confidence level of the accessory type. Range between [0,1]. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AccessoryItem" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AccessoryItem.Type">
            <summary> Type of the accessory. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AccessoryItem.Confidence">
            <summary> Confidence level of the accessory type. Range between [0,1]. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.AccessoryType">
            <summary> Type of the accessory. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AccessoryType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.AccessoryType.Headwear">
            <summary> Head wear. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AccessoryType.Glasses">
            <summary> Glasses. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AccessoryType.Mask">
            <summary> Mask. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.op_Equality(Azure.AI.Vision.Face.AccessoryType,Azure.AI.Vision.Face.AccessoryType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.AccessoryType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.op_Inequality(Azure.AI.Vision.Face.AccessoryType,Azure.AI.Vision.Face.AccessoryType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.AccessoryType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.op_Implicit(System.String)~Azure.AI.Vision.Face.AccessoryType">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.AccessoryType" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.Equals(Azure.AI.Vision.Face.AccessoryType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.AIVisionFaceModelFactory">
            <summary> Model factory for models. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceDetectionResult(System.Nullable{System.Guid},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},Azure.AI.Vision.Face.FaceRectangle,Azure.AI.Vision.Face.FaceLandmarks,Azure.AI.Vision.Face.FaceAttributes)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceDetectionResult" />. </summary>
            <param name="faceId"> Unique faceId of the detected face, created by detection API and it will expire 24 hours after the detection call. To return this, it requires 'returnFaceId' parameter to be true. </param>
            <param name="recognitionModel"> The 'recognitionModel' associated with this faceId. This is only returned when 'returnRecognitionModel' is explicitly set as true. </param>
            <param name="faceRectangle"> A rectangle area for the face location on image. </param>
            <param name="faceLandmarks"> An array of 27-point face landmarks pointing to the important positions of face components. To return this, it requires 'returnFaceLandmarks' parameter to be true. </param>
            <param name="faceAttributes"> Face attributes for detected face. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceDetectionResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceRectangle(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceRectangle" />. </summary>
            <param name="top"> The distance from the top edge if the image to the top edge of the rectangle, in pixels. </param>
            <param name="left"> The distance from the left edge if the image to the left edge of the rectangle, in pixels. </param>
            <param name="width"> The width of the rectangle, in pixels. </param>
            <param name="height"> The height of the rectangle, in pixels. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceRectangle" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceLandmarks(Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceLandmarks" />. </summary>
            <param name="pupilLeft"> The coordinates of the left eye pupil. </param>
            <param name="pupilRight"> The coordinates of the right eye pupil. </param>
            <param name="noseTip"> The coordinates of the nose tip. </param>
            <param name="mouthLeft"> The coordinates of the mouth left. </param>
            <param name="mouthRight"> The coordinates of the mouth right. </param>
            <param name="eyebrowLeftOuter"> The coordinates of the left eyebrow outer. </param>
            <param name="eyebrowLeftInner"> The coordinates of the left eyebrow inner. </param>
            <param name="eyeLeftOuter"> The coordinates of the left eye outer. </param>
            <param name="eyeLeftTop"> The coordinates of the left eye top. </param>
            <param name="eyeLeftBottom"> The coordinates of the left eye bottom. </param>
            <param name="eyeLeftInner"> The coordinates of the left eye inner. </param>
            <param name="eyebrowRightInner"> The coordinates of the right eyebrow inner. </param>
            <param name="eyebrowRightOuter"> The coordinates of the right eyebrow outer. </param>
            <param name="eyeRightInner"> The coordinates of the right eye inner. </param>
            <param name="eyeRightTop"> The coordinates of the right eye top. </param>
            <param name="eyeRightBottom"> The coordinates of the right eye bottom. </param>
            <param name="eyeRightOuter"> The coordinates of the right eye outer. </param>
            <param name="noseRootLeft"> The coordinates of the nose root left. </param>
            <param name="noseRootRight"> The coordinates of the nose root right. </param>
            <param name="noseLeftAlarTop"> The coordinates of the nose left alar top. </param>
            <param name="noseRightAlarTop"> The coordinates of the nose right alar top. </param>
            <param name="noseLeftAlarOutTip"> The coordinates of the nose left alar out tip. </param>
            <param name="noseRightAlarOutTip"> The coordinates of the nose right alar out tip. </param>
            <param name="upperLipTop"> The coordinates of the upper lip top. </param>
            <param name="upperLipBottom"> The coordinates of the upper lip bottom. </param>
            <param name="underLipTop"> The coordinates of the under lip top. </param>
            <param name="underLipBottom"> The coordinates of the under lip bottom. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceLandmarks" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LandmarkCoordinate(System.Single,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LandmarkCoordinate" />. </summary>
            <param name="x"> The horizontal component, in pixels. </param>
            <param name="y"> The vertical component, in pixels. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LandmarkCoordinate" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceAttributes(System.Nullable{System.Single},System.Nullable{System.Single},Azure.AI.Vision.Face.FacialHair,System.Nullable{Azure.AI.Vision.Face.GlassesType},Azure.AI.Vision.Face.HeadPose,Azure.AI.Vision.Face.HairProperties,Azure.AI.Vision.Face.OcclusionProperties,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.AccessoryItem},Azure.AI.Vision.Face.BlurProperties,Azure.AI.Vision.Face.ExposureProperties,Azure.AI.Vision.Face.NoiseProperties,Azure.AI.Vision.Face.MaskProperties,System.Nullable{Azure.AI.Vision.Face.QualityForRecognition})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceAttributes" />. </summary>
            <param name="age"> Age in years. </param>
            <param name="smile"> Smile intensity, a number between [0,1]. </param>
            <param name="facialHair"> Properties describing facial hair attributes. </param>
            <param name="glasses"> Glasses type if any of the face. </param>
            <param name="headPose"> 3-D roll/yaw/pitch angles for face direction. </param>
            <param name="hair"> Properties describing hair attributes. </param>
            <param name="occlusion"> Properties describing occlusions on a given face. </param>
            <param name="accessories"> Properties describing any accessories on a given face. </param>
            <param name="blur"> Properties describing any presence of blur within the image. </param>
            <param name="exposure"> Properties describing exposure level of the image. </param>
            <param name="noise"> Properties describing noise level of the image. </param>
            <param name="mask"> Properties describing the presence of a mask on a given face. </param>
            <param name="qualityForRecognition"> Properties describing the overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceAttributes" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FacialHair(System.Single,System.Single,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FacialHair" />. </summary>
            <param name="moustache"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="beard"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="sideburns"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FacialHair" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.HeadPose(System.Single,System.Single,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HeadPose" />. </summary>
            <param name="pitch"> Value of angles. </param>
            <param name="roll"> Value of angles. </param>
            <param name="yaw"> Value of angles. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.HeadPose" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.HairProperties(System.Single,System.Boolean,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.HairColor})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairProperties" />. </summary>
            <param name="bald"> A number describing confidence level of whether the person is bald. </param>
            <param name="invisible"> A boolean value describing whether the hair is visible in the image. </param>
            <param name="hairColor"> An array of candidate colors and confidence level in the presence of each. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.HairProperties" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.HairColor(Azure.AI.Vision.Face.HairColorType,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairColor" />. </summary>
            <param name="color"> Name of the hair color. </param>
            <param name="confidence"> Confidence level of the color. Range between [0,1]. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.HairColor" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.OcclusionProperties(System.Boolean,System.Boolean,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.OcclusionProperties" />. </summary>
            <param name="foreheadOccluded"> A boolean value indicating whether forehead is occluded. </param>
            <param name="eyeOccluded"> A boolean value indicating whether eyes are occluded. </param>
            <param name="mouthOccluded"> A boolean value indicating whether the mouth is occluded. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.OcclusionProperties" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.AccessoryItem(Azure.AI.Vision.Face.AccessoryType,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AccessoryItem" />. </summary>
            <param name="type"> Type of the accessory. </param>
            <param name="confidence"> Confidence level of the accessory type. Range between [0,1]. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.AccessoryItem" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.BlurProperties(Azure.AI.Vision.Face.BlurLevel,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.BlurProperties" />. </summary>
            <param name="blurLevel"> An enum value indicating level of blurriness. </param>
            <param name="value"> A number indicating level of blurriness ranging from 0 to 1. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.BlurProperties" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.ExposureProperties(Azure.AI.Vision.Face.ExposureLevel,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.ExposureProperties" />. </summary>
            <param name="exposureLevel"> An enum value indicating level of exposure. </param>
            <param name="value"> A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.ExposureProperties" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.NoiseProperties(Azure.AI.Vision.Face.NoiseLevel,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.NoiseProperties" />. </summary>
            <param name="noiseLevel"> An enum value indicating level of noise. </param>
            <param name="value"> A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.NoiseProperties" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.MaskProperties(System.Boolean,Azure.AI.Vision.Face.MaskType)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.MaskProperties" />. </summary>
            <param name="noseAndMouthCovered"> A boolean value indicating whether nose and mouth are covered. </param>
            <param name="type"> Type of the mask. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.MaskProperties" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceFindSimilarResult(System.Single,System.Nullable{System.Guid},System.Nullable{System.Guid})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceFindSimilarResult" />. </summary>
            <param name="confidence"> Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1]. </param>
            <param name="faceId"> faceId of candidate face when find by faceIds. faceId is created by "Detect" and will expire 24 hours after the detection call. </param>
            <param name="persistedFaceId"> persistedFaceId of candidate face when find by faceListId or largeFaceListId. persistedFaceId in face list/large face list is persisted and will not expire. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceFindSimilarResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceVerificationResult(System.Boolean,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceVerificationResult" />. </summary>
            <param name="isIdentical"> True if the two faces belong to the same person or the face belongs to the person, otherwise false. </param>
            <param name="confidence"> A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override 'isIdentical' and fine-tune the result on their own data. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceVerificationResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.FaceGroupingResult(System.Collections.Generic.IEnumerable{System.Collections.Generic.IList{System.Guid}},System.Collections.Generic.IEnumerable{System.Guid})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceGroupingResult" />. </summary>
            <param name="groups"> A partition of the original faces based on face similarity. Groups are ranked by number of faces. </param>
            <param name="messyGroup"> Face ids array of faces that cannot find any similar faces from original faces. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.FaceGroupingResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.CreateLivenessSessionContent(Azure.AI.Vision.Face.LivenessOperationMode,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String,System.Nullable{System.Int32})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionContent" />. </summary>
            <param name="livenessOperationMode"> Type of liveness mode the client should follow. </param>
            <param name="sendResultsToClient"> Whether or not to allow a '200 - Success' response body to be sent to the client, which may be undesirable for security reasons. Default is false, clients will receive a '204 - NoContent' empty body response. Regardless of selection, calling Session GetResult will always contain a response body enabling business logic to be implemented. </param>
            <param name="deviceCorrelationIdSetInClient"> Whether or not to allow client to set their own 'deviceCorrelationId' via the Vision SDK. Default is false, and 'deviceCorrelationId' must be set in this request body. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionContent" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.CreateLivenessSessionResult(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionResult" />. </summary>
            <param name="sessionId"> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </param>
            <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessSession(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Boolean,System.String,System.Nullable{System.Int32},Azure.AI.Vision.Face.FaceSessionStatus,Azure.AI.Vision.Face.LivenessSessionAuditEntry)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSession" />. </summary>
            <param name="id"> The unique ID to reference this session. </param>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionStartDateTime"> DateTime when this session was started by the client. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <param name="status"> The current status of the session. </param>
            <param name="result"> The latest session audit result only populated if status == 'ResultAvailable'. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessSession" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessSessionAuditEntry(System.Int64,System.String,System.String,System.String,System.DateTimeOffset,Azure.AI.Vision.Face.AuditRequestInfo,Azure.AI.Vision.Face.AuditLivenessResponseInfo,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionAuditEntry" />. </summary>
            <param name="id"> The unique id to refer to this audit request. Use this id with the 'start' query parameter to continue on to the next page of audit results. </param>
            <param name="sessionId"> The unique sessionId of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding session DELETE operation. </param>
            <param name="requestId"> The unique requestId that is returned by the service to the client in the 'apim-request-id' header. </param>
            <param name="clientRequestId"> The unique clientRequestId that is sent by the client in the 'client-request-id' header. </param>
            <param name="receivedDateTime"> The UTC DateTime that the request was received. </param>
            <param name="request"> The request of this entry. </param>
            <param name="response"> The response of this entry. </param>
            <param name="digest"> The server calculated digest for this request. If the client reported digest differs from the server calculated digest, then the message integrity between the client and service has been compromised and the result should not be trusted. For more information, see how to guides on how to leverage this value to secure your end-to-end solution. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessSessionAuditEntry" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.AuditRequestInfo(System.String,System.String,System.Nullable{System.Int64},System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditRequestInfo" />. </summary>
            <param name="url"> The relative URL and query of the liveness request. </param>
            <param name="method"> The HTTP method of the request (i.e., GET, POST, DELETE). </param>
            <param name="contentLength"> The length of the request body in bytes. </param>
            <param name="contentType"> The content type of the request. </param>
            <param name="userAgent"> The user agent used to submit the request. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.AuditRequestInfo" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.AuditLivenessResponseInfo(Azure.AI.Vision.Face.LivenessResponseBody,System.Int32,System.Int64)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditLivenessResponseInfo" />. </summary>
            <param name="body"> The response body. The schema of this field will depend on the request.url and request.method used by the client. </param>
            <param name="statusCode"> The HTTP status code returned to the client. </param>
            <param name="latencyInMilliseconds"> The server measured latency for this request in milliseconds. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.AuditLivenessResponseInfo" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessResponseBody(System.Nullable{Azure.AI.Vision.Face.FaceLivenessDecision},Azure.AI.Vision.Face.LivenessOutputsTarget,System.Nullable{Azure.AI.Vision.Face.LivenessModel},Azure.AI.Vision.Face.LivenessWithVerifyOutputs,System.Collections.Generic.IReadOnlyDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessResponseBody" />. </summary>
            <param name="livenessDecision"> The liveness classification for the target face. </param>
            <param name="target"> Specific targets used for liveness classification. </param>
            <param name="modelVersionUsed"> The model version used for liveness classification. </param>
            <param name="verifyResult"> The face verification output. Only available when the request is liveness with verify. </param>
            <param name="additionalProperties"> Additional Properties. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessResponseBody" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessOutputsTarget(Azure.AI.Vision.Face.FaceRectangle,System.String,System.Int32,Azure.AI.Vision.Face.FaceImageType)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessOutputsTarget" />. </summary>
            <param name="faceRectangle"> The face region where the liveness classification was made on. </param>
            <param name="fileName"> The file name which contains the face rectangle where the liveness classification was made on. </param>
            <param name="timeOffsetWithinFile"> The time offset within the file of the frame which contains the face rectangle where the liveness classification was made on. </param>
            <param name="imageType"> The image type which contains the face rectangle where the liveness classification was made on. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessOutputsTarget" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessWithVerifyOutputs(Azure.AI.Vision.Face.LivenessWithVerifyImage,System.Single,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyOutputs" />. </summary>
            <param name="verifyImage"> The detail of face for verification. </param>
            <param name="matchConfidence"> The target face liveness face and comparison image face verification confidence. </param>
            <param name="isIdentical"> Whether the target liveness face and comparison image face match. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyOutputs" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessWithVerifyImage(Azure.AI.Vision.Face.FaceRectangle,Azure.AI.Vision.Face.QualityForRecognition)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyImage" />. </summary>
            <param name="faceRectangle"> The face region where the comparison image's classification was made. </param>
            <param name="qualityForRecognition"> Quality of face image for recognition. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyImage" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessSessionItem(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Boolean,System.String,System.Nullable{System.Int32})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionItem" />. </summary>
            <param name="id"> The unique ID to reference this session. </param>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionStartDateTime"> DateTime when this session was started by the client. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessSessionItem" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.CreateLivenessWithVerifySessionResult(System.String,System.String,Azure.AI.Vision.Face.LivenessWithVerifyImage)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult" />. </summary>
            <param name="sessionId"> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </param>
            <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
            <param name="verifyImage"> The detail of face for verification. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult" /> instance for mocking. </returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AIVisionFaceModelFactory.LivenessWithVerifySession(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Boolean,System.String,System.Nullable{System.Int32},Azure.AI.Vision.Face.FaceSessionStatus,Azure.AI.Vision.Face.LivenessSessionAuditEntry)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifySession" />. </summary>
            <param name="id"> The unique ID to reference this session. </param>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionStartDateTime"> DateTime when this session was started by the client. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <param name="status"> The current status of the session. </param>
            <param name="result"> The latest session audit result only populated if status == 'ResultAvailable'. </param>
            <returns> A new <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifySession" /> instance for mocking. </returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.AuditLivenessResponseInfo">
            <summary> Audit entry for a response in the session. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.#ctor(Azure.AI.Vision.Face.LivenessResponseBody,System.Int32,System.Int64)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditLivenessResponseInfo" />. </summary>
            <param name="body"> The response body. The schema of this field will depend on the request.url and request.method used by the client. </param>
            <param name="statusCode"> The HTTP status code returned to the client. </param>
            <param name="latencyInMilliseconds"> The server measured latency for this request in milliseconds. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="body" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.#ctor(Azure.AI.Vision.Face.LivenessResponseBody,System.Int32,System.Int64,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditLivenessResponseInfo" />. </summary>
            <param name="body"> The response body. The schema of this field will depend on the request.url and request.method used by the client. </param>
            <param name="statusCode"> The HTTP status code returned to the client. </param>
            <param name="latencyInMilliseconds"> The server measured latency for this request in milliseconds. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditLivenessResponseInfo" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditLivenessResponseInfo.Body">
            <summary> The response body. The schema of this field will depend on the request.url and request.method used by the client. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditLivenessResponseInfo.StatusCode">
            <summary> The HTTP status code returned to the client. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditLivenessResponseInfo.LatencyInMilliseconds">
            <summary> The server measured latency for this request in milliseconds. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.AuditRequestInfo">
            <summary> Audit entry for a request in the session. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.#ctor(System.String,System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditRequestInfo" />. </summary>
            <param name="url"> The relative URL and query of the liveness request. </param>
            <param name="method"> The HTTP method of the request (i.e., GET, POST, DELETE). </param>
            <param name="contentType"> The content type of the request. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="url" />, <paramref name="method" /> or <paramref name="contentType" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.#ctor(System.String,System.String,System.Nullable{System.Int64},System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditRequestInfo" />. </summary>
            <param name="url"> The relative URL and query of the liveness request. </param>
            <param name="method"> The HTTP method of the request (i.e., GET, POST, DELETE). </param>
            <param name="contentLength"> The length of the request body in bytes. </param>
            <param name="contentType"> The content type of the request. </param>
            <param name="userAgent"> The user agent used to submit the request. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.AuditRequestInfo" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditRequestInfo.Url">
            <summary> The relative URL and query of the liveness request. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditRequestInfo.Method">
            <summary> The HTTP method of the request (i.e., GET, POST, DELETE). </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditRequestInfo.ContentLength">
            <summary> The length of the request body in bytes. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditRequestInfo.ContentType">
            <summary> The content type of the request. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.AuditRequestInfo.UserAgent">
            <summary> The user agent used to submit the request. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions">
            <summary> Client options for Azure.AI.Vision.Face library clients. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions.ServiceVersion">
            <summary> The version of the service to use. </summary>
        </member>
        <member name="F:Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions.ServiceVersion.V1_1_Preview_1">
            <summary> Service version "v1.1-preview.1". </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions.#ctor(Azure.AI.Vision.Face.AzureAIVisionFaceClientOptions.ServiceVersion)">
            <summary> Initializes new instance of AzureAIVisionFaceClientOptions. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.BlurLevel">
            <summary> Indicates level of blurriness. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.BlurLevel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.BlurLevel.Low">
            <summary> Low blur level. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.BlurLevel.Medium">
            <summary> Medium blur level. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.BlurLevel.High">
            <summary> High blur level. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.op_Equality(Azure.AI.Vision.Face.BlurLevel,Azure.AI.Vision.Face.BlurLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.BlurLevel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.op_Inequality(Azure.AI.Vision.Face.BlurLevel,Azure.AI.Vision.Face.BlurLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.BlurLevel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.op_Implicit(System.String)~Azure.AI.Vision.Face.BlurLevel">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.BlurLevel" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.Equals(Azure.AI.Vision.Face.BlurLevel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurLevel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.BlurProperties">
            <summary> Properties describing any presence of blur within the image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.#ctor(Azure.AI.Vision.Face.BlurLevel,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.BlurProperties" />. </summary>
            <param name="blurLevel"> An enum value indicating level of blurriness. </param>
            <param name="value"> A number indicating level of blurriness ranging from 0 to 1. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.#ctor(Azure.AI.Vision.Face.BlurLevel,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.BlurProperties" />. </summary>
            <param name="blurLevel"> An enum value indicating level of blurriness. </param>
            <param name="value"> A number indicating level of blurriness ranging from 0 to 1. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.BlurProperties" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.BlurProperties.BlurLevel">
            <summary> An enum value indicating level of blurriness. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.BlurProperties.Value">
            <summary> A number indicating level of blurriness ranging from 0 to 1. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.CreateLivenessSessionContent">
            <summary> Request for creating liveness session. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.#ctor(Azure.AI.Vision.Face.LivenessOperationMode)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionContent" />. </summary>
            <param name="livenessOperationMode"> Type of liveness mode the client should follow. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.#ctor(Azure.AI.Vision.Face.LivenessOperationMode,System.Nullable{System.Boolean},System.Nullable{System.Boolean},System.String,System.Nullable{System.Int32},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionContent" />. </summary>
            <param name="livenessOperationMode"> Type of liveness mode the client should follow. </param>
            <param name="sendResultsToClient"> Whether or not to allow a '200 - Success' response body to be sent to the client, which may be undesirable for security reasons. Default is false, clients will receive a '204 - NoContent' empty body response. Regardless of selection, calling Session GetResult will always contain a response body enabling business logic to be implemented. </param>
            <param name="deviceCorrelationIdSetInClient"> Whether or not to allow client to set their own 'deviceCorrelationId' via the Vision SDK. Default is false, and 'deviceCorrelationId' must be set in this request body. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionContent" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionContent.LivenessOperationMode">
            <summary> Type of liveness mode the client should follow. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionContent.SendResultsToClient">
            <summary> Whether or not to allow a '200 - Success' response body to be sent to the client, which may be undesirable for security reasons. Default is false, clients will receive a '204 - NoContent' empty body response. Regardless of selection, calling Session GetResult will always contain a response body enabling business logic to be implemented. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionContent.DeviceCorrelationIdSetInClient">
            <summary> Whether or not to allow client to set their own 'deviceCorrelationId' via the Vision SDK. Default is false, and 'deviceCorrelationId' must be set in this request body. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionContent.DeviceCorrelationId">
            <summary> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionContent.AuthTokenTimeToLiveInSeconds">
            <summary> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.CreateLivenessSessionResult">
            <summary> Response of liveness session creation. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionResult" />. </summary>
            <param name="sessionId"> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </param>
            <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> or <paramref name="authToken" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.#ctor(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionResult" />. </summary>
            <param name="sessionId"> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </param>
            <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessSessionResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionResult.SessionId">
            <summary> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessSessionResult.AuthToken">
            <summary> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent">
            <summary> Request of liveness with verify session creation. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.#ctor(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.IO.Stream)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent" />. </summary>
            <param name="parameters"> The parameters for creating session. </param>
            <param name="verifyImage"> The image stream for verify. Content-Disposition header field for this part must have filename. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="parameters" /> or <paramref name="verifyImage" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.#ctor(Azure.AI.Vision.Face.CreateLivenessSessionContent,System.IO.Stream,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent" />. </summary>
            <param name="parameters"> The parameters for creating session. </param>
            <param name="verifyImage"> The image stream for verify. Content-Disposition header field for this part must have filename. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.Parameters">
            <summary> The parameters for creating session. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.VerifyImage">
            <summary> The image stream for verify. Content-Disposition header field for this part must have filename. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult">
            <summary> Response of liveness session with verify creation with verify image provided. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.#ctor(System.String,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult" />. </summary>
            <param name="sessionId"> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </param>
            <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" /> or <paramref name="authToken" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.#ctor(System.String,System.String,Azure.AI.Vision.Face.LivenessWithVerifyImage,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult" />. </summary>
            <param name="sessionId"> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </param>
            <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
            <param name="verifyImage"> The detail of face for verification. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.SessionId">
            <summary> The unique session ID of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding Session DELETE operation. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.AuthToken">
            <summary> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.VerifyImage">
            <summary> The detail of face for verification. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.DetectFromUrlRequest">
            <summary> The DetectFromUrlRequest. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.#ctor(System.Uri)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.DetectFromUrlRequest" />. </summary>
            <param name="uri"> URL of input image. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="uri" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.#ctor(System.Uri,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.DetectFromUrlRequest" />. </summary>
            <param name="uri"> URL of input image. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.DetectFromUrlRequest" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.DetectFromUrlRequest.Uri">
            <summary> URL of input image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.ExposureLevel">
            <summary> Indicates level of exposure. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.ExposureLevel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.ExposureLevel.UnderExposure">
            <summary> Low exposure level. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.ExposureLevel.GoodExposure">
            <summary> Good exposure level. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.ExposureLevel.OverExposure">
            <summary> High exposure level. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.op_Equality(Azure.AI.Vision.Face.ExposureLevel,Azure.AI.Vision.Face.ExposureLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.ExposureLevel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.op_Inequality(Azure.AI.Vision.Face.ExposureLevel,Azure.AI.Vision.Face.ExposureLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.ExposureLevel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.op_Implicit(System.String)~Azure.AI.Vision.Face.ExposureLevel">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.ExposureLevel" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.Equals(Azure.AI.Vision.Face.ExposureLevel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureLevel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.ExposureProperties">
            <summary> Properties describing exposure level of the image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.#ctor(Azure.AI.Vision.Face.ExposureLevel,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.ExposureProperties" />. </summary>
            <param name="exposureLevel"> An enum value indicating level of exposure. </param>
            <param name="value"> A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.#ctor(Azure.AI.Vision.Face.ExposureLevel,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.ExposureProperties" />. </summary>
            <param name="exposureLevel"> An enum value indicating level of exposure. </param>
            <param name="value"> A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.ExposureProperties" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.ExposureProperties.ExposureLevel">
            <summary> An enum value indicating level of exposure. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.ExposureProperties.Value">
            <summary> A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceAttributes">
            <summary> Face attributes for the detected face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceAttributes" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.#ctor(System.Nullable{System.Single},System.Nullable{System.Single},Azure.AI.Vision.Face.FacialHair,System.Nullable{Azure.AI.Vision.Face.GlassesType},Azure.AI.Vision.Face.HeadPose,Azure.AI.Vision.Face.HairProperties,Azure.AI.Vision.Face.OcclusionProperties,System.Collections.Generic.IReadOnlyList{Azure.AI.Vision.Face.AccessoryItem},Azure.AI.Vision.Face.BlurProperties,Azure.AI.Vision.Face.ExposureProperties,Azure.AI.Vision.Face.NoiseProperties,Azure.AI.Vision.Face.MaskProperties,System.Nullable{Azure.AI.Vision.Face.QualityForRecognition},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceAttributes" />. </summary>
            <param name="age"> Age in years. </param>
            <param name="smile"> Smile intensity, a number between [0,1]. </param>
            <param name="facialHair"> Properties describing facial hair attributes. </param>
            <param name="glasses"> Glasses type if any of the face. </param>
            <param name="headPose"> 3-D roll/yaw/pitch angles for face direction. </param>
            <param name="hair"> Properties describing hair attributes. </param>
            <param name="occlusion"> Properties describing occlusions on a given face. </param>
            <param name="accessories"> Properties describing any accessories on a given face. </param>
            <param name="blur"> Properties describing any presence of blur within the image. </param>
            <param name="exposure"> Properties describing exposure level of the image. </param>
            <param name="noise"> Properties describing noise level of the image. </param>
            <param name="mask"> Properties describing the presence of a mask on a given face. </param>
            <param name="qualityForRecognition"> Properties describing the overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Age">
            <summary> Age in years. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Smile">
            <summary> Smile intensity, a number between [0,1]. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.FacialHair">
            <summary> Properties describing facial hair attributes. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Glasses">
            <summary> Glasses type if any of the face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.HeadPose">
            <summary> 3-D roll/yaw/pitch angles for face direction. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Hair">
            <summary> Properties describing hair attributes. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Occlusion">
            <summary> Properties describing occlusions on a given face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Accessories">
            <summary> Properties describing any accessories on a given face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Blur">
            <summary> Properties describing any presence of blur within the image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Exposure">
            <summary> Properties describing exposure level of the image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Noise">
            <summary> Properties describing noise level of the image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.Mask">
            <summary> Properties describing the presence of a mask on a given face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceAttributes.QualityForRecognition">
            <summary> Properties describing the overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceDetectionModel">
            <summary> The detection model for the face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceDetectionModel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionModel.Detection01">
            <summary> The default detection model. Recommend for near frontal face detection. For scenarios with exceptionally large angle (head-pose) faces, occluded faces or wrong image orientation, the faces in such cases may not be detected. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionModel.Detection02">
            <summary> Detection model released in 2019 May with improved accuracy especially on small, side and blurry faces. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionModel.Detection03">
            <summary> Detection model released in 2021 February with improved accuracy especially on small faces. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.op_Equality(Azure.AI.Vision.Face.FaceDetectionModel,Azure.AI.Vision.Face.FaceDetectionModel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceDetectionModel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.op_Inequality(Azure.AI.Vision.Face.FaceDetectionModel,Azure.AI.Vision.Face.FaceDetectionModel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceDetectionModel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.op_Implicit(System.String)~Azure.AI.Vision.Face.FaceDetectionModel">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FaceDetectionModel" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.Equals(Azure.AI.Vision.Face.FaceDetectionModel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionModel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceDetectionResult">
            <summary> Response for detect API. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.#ctor(Azure.AI.Vision.Face.FaceRectangle)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceDetectionResult" />. </summary>
            <param name="faceRectangle"> A rectangle area for the face location on image. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceRectangle" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.#ctor(System.Nullable{System.Guid},System.Nullable{Azure.AI.Vision.Face.FaceRecognitionModel},Azure.AI.Vision.Face.FaceRectangle,Azure.AI.Vision.Face.FaceLandmarks,Azure.AI.Vision.Face.FaceAttributes,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceDetectionResult" />. </summary>
            <param name="faceId"> Unique faceId of the detected face, created by detection API and it will expire 24 hours after the detection call. To return this, it requires 'returnFaceId' parameter to be true. </param>
            <param name="recognitionModel"> The 'recognitionModel' associated with this faceId. This is only returned when 'returnRecognitionModel' is explicitly set as true. </param>
            <param name="faceRectangle"> A rectangle area for the face location on image. </param>
            <param name="faceLandmarks"> An array of 27-point face landmarks pointing to the important positions of face components. To return this, it requires 'returnFaceLandmarks' parameter to be true. </param>
            <param name="faceAttributes"> Face attributes for detected face. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceDetectionResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionResult.FaceId">
            <summary> Unique faceId of the detected face, created by detection API and it will expire 24 hours after the detection call. To return this, it requires 'returnFaceId' parameter to be true. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionResult.RecognitionModel">
            <summary> The 'recognitionModel' associated with this faceId. This is only returned when 'returnRecognitionModel' is explicitly set as true. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionResult.FaceRectangle">
            <summary> A rectangle area for the face location on image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionResult.FaceLandmarks">
            <summary> An array of 27-point face landmarks pointing to the important positions of face components. To return this, it requires 'returnFaceLandmarks' parameter to be true. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceDetectionResult.FaceAttributes">
            <summary> Face attributes for detected face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceFindSimilarResult">
            <summary> Response body for find similar face operation. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.#ctor(System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceFindSimilarResult" />. </summary>
            <param name="confidence"> Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1]. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.#ctor(System.Single,System.Nullable{System.Guid},System.Nullable{System.Guid},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceFindSimilarResult" />. </summary>
            <param name="confidence"> Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1]. </param>
            <param name="faceId"> faceId of candidate face when find by faceIds. faceId is created by "Detect" and will expire 24 hours after the detection call. </param>
            <param name="persistedFaceId"> persistedFaceId of candidate face when find by faceListId or largeFaceListId. persistedFaceId in face list/large face list is persisted and will not expire. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceFindSimilarResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceFindSimilarResult.Confidence">
            <summary> Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1]. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceFindSimilarResult.FaceId">
            <summary> faceId of candidate face when find by faceIds. faceId is created by "Detect" and will expire 24 hours after the detection call. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceFindSimilarResult.PersistedFaceId">
            <summary> persistedFaceId of candidate face when find by faceListId or largeFaceListId. persistedFaceId in face list/large face list is persisted and will not expire. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceGroupingResult">
            <summary> Response body for group face operation. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.IList{System.Guid}},System.Collections.Generic.IEnumerable{System.Guid})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceGroupingResult" />. </summary>
            <param name="groups"> A partition of the original faces based on face similarity. Groups are ranked by number of faces. </param>
            <param name="messyGroup"> Face ids array of faces that cannot find any similar faces from original faces. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="groups" /> or <paramref name="messyGroup" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.#ctor(System.Collections.Generic.IReadOnlyList{System.Collections.Generic.IList{System.Guid}},System.Collections.Generic.IReadOnlyList{System.Guid},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceGroupingResult" />. </summary>
            <param name="groups"> A partition of the original faces based on face similarity. Groups are ranked by number of faces. </param>
            <param name="messyGroup"> Face ids array of faces that cannot find any similar faces from original faces. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceGroupingResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceGroupingResult.Groups">
            <summary> A partition of the original faces based on face similarity. Groups are ranked by number of faces. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceGroupingResult.MessyGroup">
            <summary> Face ids array of faces that cannot find any similar faces from original faces. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceImageType">
            <summary> The type of image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceImageType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceImageType.Color">
            <summary> Color image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceImageType.Infrared">
            <summary> Infrared image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceImageType.Depth">
            <summary> Depth image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.op_Equality(Azure.AI.Vision.Face.FaceImageType,Azure.AI.Vision.Face.FaceImageType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceImageType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.op_Inequality(Azure.AI.Vision.Face.FaceImageType,Azure.AI.Vision.Face.FaceImageType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceImageType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.op_Implicit(System.String)~Azure.AI.Vision.Face.FaceImageType">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FaceImageType" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.Equals(Azure.AI.Vision.Face.FaceImageType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceImageType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceLandmarks">
            <summary> A collection of 27-point face landmarks pointing to the important positions of face components. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.#ctor(Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceLandmarks" />. </summary>
            <param name="pupilLeft"> The coordinates of the left eye pupil. </param>
            <param name="pupilRight"> The coordinates of the right eye pupil. </param>
            <param name="noseTip"> The coordinates of the nose tip. </param>
            <param name="mouthLeft"> The coordinates of the mouth left. </param>
            <param name="mouthRight"> The coordinates of the mouth right. </param>
            <param name="eyebrowLeftOuter"> The coordinates of the left eyebrow outer. </param>
            <param name="eyebrowLeftInner"> The coordinates of the left eyebrow inner. </param>
            <param name="eyeLeftOuter"> The coordinates of the left eye outer. </param>
            <param name="eyeLeftTop"> The coordinates of the left eye top. </param>
            <param name="eyeLeftBottom"> The coordinates of the left eye bottom. </param>
            <param name="eyeLeftInner"> The coordinates of the left eye inner. </param>
            <param name="eyebrowRightInner"> The coordinates of the right eyebrow inner. </param>
            <param name="eyebrowRightOuter"> The coordinates of the right eyebrow outer. </param>
            <param name="eyeRightInner"> The coordinates of the right eye inner. </param>
            <param name="eyeRightTop"> The coordinates of the right eye top. </param>
            <param name="eyeRightBottom"> The coordinates of the right eye bottom. </param>
            <param name="eyeRightOuter"> The coordinates of the right eye outer. </param>
            <param name="noseRootLeft"> The coordinates of the nose root left. </param>
            <param name="noseRootRight"> The coordinates of the nose root right. </param>
            <param name="noseLeftAlarTop"> The coordinates of the nose left alar top. </param>
            <param name="noseRightAlarTop"> The coordinates of the nose right alar top. </param>
            <param name="noseLeftAlarOutTip"> The coordinates of the nose left alar out tip. </param>
            <param name="noseRightAlarOutTip"> The coordinates of the nose right alar out tip. </param>
            <param name="upperLipTop"> The coordinates of the upper lip top. </param>
            <param name="upperLipBottom"> The coordinates of the upper lip bottom. </param>
            <param name="underLipTop"> The coordinates of the under lip top. </param>
            <param name="underLipBottom"> The coordinates of the under lip bottom. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="pupilLeft" />, <paramref name="pupilRight" />, <paramref name="noseTip" />, <paramref name="mouthLeft" />, <paramref name="mouthRight" />, <paramref name="eyebrowLeftOuter" />, <paramref name="eyebrowLeftInner" />, <paramref name="eyeLeftOuter" />, <paramref name="eyeLeftTop" />, <paramref name="eyeLeftBottom" />, <paramref name="eyeLeftInner" />, <paramref name="eyebrowRightInner" />, <paramref name="eyebrowRightOuter" />, <paramref name="eyeRightInner" />, <paramref name="eyeRightTop" />, <paramref name="eyeRightBottom" />, <paramref name="eyeRightOuter" />, <paramref name="noseRootLeft" />, <paramref name="noseRootRight" />, <paramref name="noseLeftAlarTop" />, <paramref name="noseRightAlarTop" />, <paramref name="noseLeftAlarOutTip" />, <paramref name="noseRightAlarOutTip" />, <paramref name="upperLipTop" />, <paramref name="upperLipBottom" />, <paramref name="underLipTop" /> or <paramref name="underLipBottom" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.#ctor(Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,Azure.AI.Vision.Face.LandmarkCoordinate,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceLandmarks" />. </summary>
            <param name="pupilLeft"> The coordinates of the left eye pupil. </param>
            <param name="pupilRight"> The coordinates of the right eye pupil. </param>
            <param name="noseTip"> The coordinates of the nose tip. </param>
            <param name="mouthLeft"> The coordinates of the mouth left. </param>
            <param name="mouthRight"> The coordinates of the mouth right. </param>
            <param name="eyebrowLeftOuter"> The coordinates of the left eyebrow outer. </param>
            <param name="eyebrowLeftInner"> The coordinates of the left eyebrow inner. </param>
            <param name="eyeLeftOuter"> The coordinates of the left eye outer. </param>
            <param name="eyeLeftTop"> The coordinates of the left eye top. </param>
            <param name="eyeLeftBottom"> The coordinates of the left eye bottom. </param>
            <param name="eyeLeftInner"> The coordinates of the left eye inner. </param>
            <param name="eyebrowRightInner"> The coordinates of the right eyebrow inner. </param>
            <param name="eyebrowRightOuter"> The coordinates of the right eyebrow outer. </param>
            <param name="eyeRightInner"> The coordinates of the right eye inner. </param>
            <param name="eyeRightTop"> The coordinates of the right eye top. </param>
            <param name="eyeRightBottom"> The coordinates of the right eye bottom. </param>
            <param name="eyeRightOuter"> The coordinates of the right eye outer. </param>
            <param name="noseRootLeft"> The coordinates of the nose root left. </param>
            <param name="noseRootRight"> The coordinates of the nose root right. </param>
            <param name="noseLeftAlarTop"> The coordinates of the nose left alar top. </param>
            <param name="noseRightAlarTop"> The coordinates of the nose right alar top. </param>
            <param name="noseLeftAlarOutTip"> The coordinates of the nose left alar out tip. </param>
            <param name="noseRightAlarOutTip"> The coordinates of the nose right alar out tip. </param>
            <param name="upperLipTop"> The coordinates of the upper lip top. </param>
            <param name="upperLipBottom"> The coordinates of the upper lip bottom. </param>
            <param name="underLipTop"> The coordinates of the under lip top. </param>
            <param name="underLipBottom"> The coordinates of the under lip bottom. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceLandmarks" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.PupilLeft">
            <summary> The coordinates of the left eye pupil. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.PupilRight">
            <summary> The coordinates of the right eye pupil. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseTip">
            <summary> The coordinates of the nose tip. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.MouthLeft">
            <summary> The coordinates of the mouth left. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.MouthRight">
            <summary> The coordinates of the mouth right. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyebrowLeftOuter">
            <summary> The coordinates of the left eyebrow outer. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyebrowLeftInner">
            <summary> The coordinates of the left eyebrow inner. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeLeftOuter">
            <summary> The coordinates of the left eye outer. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeLeftTop">
            <summary> The coordinates of the left eye top. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeLeftBottom">
            <summary> The coordinates of the left eye bottom. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeLeftInner">
            <summary> The coordinates of the left eye inner. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyebrowRightInner">
            <summary> The coordinates of the right eyebrow inner. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyebrowRightOuter">
            <summary> The coordinates of the right eyebrow outer. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeRightInner">
            <summary> The coordinates of the right eye inner. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeRightTop">
            <summary> The coordinates of the right eye top. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeRightBottom">
            <summary> The coordinates of the right eye bottom. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.EyeRightOuter">
            <summary> The coordinates of the right eye outer. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseRootLeft">
            <summary> The coordinates of the nose root left. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseRootRight">
            <summary> The coordinates of the nose root right. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseLeftAlarTop">
            <summary> The coordinates of the nose left alar top. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseRightAlarTop">
            <summary> The coordinates of the nose right alar top. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseLeftAlarOutTip">
            <summary> The coordinates of the nose left alar out tip. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.NoseRightAlarOutTip">
            <summary> The coordinates of the nose right alar out tip. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.UpperLipTop">
            <summary> The coordinates of the upper lip top. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.UpperLipBottom">
            <summary> The coordinates of the upper lip bottom. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.UnderLipTop">
            <summary> The coordinates of the under lip top. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLandmarks.UnderLipBottom">
            <summary> The coordinates of the under lip bottom. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceLivenessDecision">
            <summary> The outcome of the liveness classification. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceLivenessDecision" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLivenessDecision.Uncertain">
            <summary> The algorithm could not classify the target face as either real or spoof. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLivenessDecision.RealFace">
            <summary> The algorithm has classified the target face as real. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceLivenessDecision.SpoofFace">
            <summary> The algorithm has classified the target face as a spoof. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.op_Equality(Azure.AI.Vision.Face.FaceLivenessDecision,Azure.AI.Vision.Face.FaceLivenessDecision)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceLivenessDecision" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.op_Inequality(Azure.AI.Vision.Face.FaceLivenessDecision,Azure.AI.Vision.Face.FaceLivenessDecision)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceLivenessDecision" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.op_Implicit(System.String)~Azure.AI.Vision.Face.FaceLivenessDecision">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FaceLivenessDecision" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.Equals(Azure.AI.Vision.Face.FaceLivenessDecision)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLivenessDecision.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceRecognitionModel">
            <summary> The recognition model for the face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceRecognitionModel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRecognitionModel.Recognition01">
            <summary> The default recognition model for "Detect". All those faceIds created before 2019 March are bonded with this recognition model. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRecognitionModel.Recognition02">
            <summary> Recognition model released in 2019 March. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRecognitionModel.Recognition03">
            <summary> Recognition model released in 2020 May. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRecognitionModel.Recognition04">
            <summary> Recognition model released in 2021 February. It's recommended to use this recognition model for better recognition accuracy. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.op_Equality(Azure.AI.Vision.Face.FaceRecognitionModel,Azure.AI.Vision.Face.FaceRecognitionModel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceRecognitionModel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.op_Inequality(Azure.AI.Vision.Face.FaceRecognitionModel,Azure.AI.Vision.Face.FaceRecognitionModel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceRecognitionModel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.op_Implicit(System.String)~Azure.AI.Vision.Face.FaceRecognitionModel">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FaceRecognitionModel" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.Equals(Azure.AI.Vision.Face.FaceRecognitionModel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRecognitionModel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceRectangle">
            <summary> A rectangle within which a face can be found. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.#ctor(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceRectangle" />. </summary>
            <param name="top"> The distance from the top edge if the image to the top edge of the rectangle, in pixels. </param>
            <param name="left"> The distance from the left edge if the image to the left edge of the rectangle, in pixels. </param>
            <param name="width"> The width of the rectangle, in pixels. </param>
            <param name="height"> The height of the rectangle, in pixels. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.#ctor(System.Int32,System.Int32,System.Int32,System.Int32,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceRectangle" />. </summary>
            <param name="top"> The distance from the top edge if the image to the top edge of the rectangle, in pixels. </param>
            <param name="left"> The distance from the left edge if the image to the left edge of the rectangle, in pixels. </param>
            <param name="width"> The width of the rectangle, in pixels. </param>
            <param name="height"> The height of the rectangle, in pixels. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceRectangle" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRectangle.Top">
            <summary> The distance from the top edge if the image to the top edge of the rectangle, in pixels. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRectangle.Left">
            <summary> The distance from the left edge if the image to the left edge of the rectangle, in pixels. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRectangle.Width">
            <summary> The width of the rectangle, in pixels. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceRectangle.Height">
            <summary> The height of the rectangle, in pixels. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceSessionStatus">
            <summary> The current status of the session. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceSessionStatus" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceSessionStatus.NotStarted">
            <summary> Session has not started. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceSessionStatus.Started">
            <summary> Session has started. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceSessionStatus.ResultAvailable">
            <summary> Session has available result. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.op_Equality(Azure.AI.Vision.Face.FaceSessionStatus,Azure.AI.Vision.Face.FaceSessionStatus)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceSessionStatus" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.op_Inequality(Azure.AI.Vision.Face.FaceSessionStatus,Azure.AI.Vision.Face.FaceSessionStatus)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FaceSessionStatus" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.op_Implicit(System.String)~Azure.AI.Vision.Face.FaceSessionStatus">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FaceSessionStatus" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.Equals(Azure.AI.Vision.Face.FaceSessionStatus)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceSessionStatus.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FaceVerificationResult">
            <summary> Verify result. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.#ctor(System.Boolean,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceVerificationResult" />. </summary>
            <param name="isIdentical"> True if the two faces belong to the same person or the face belongs to the person, otherwise false. </param>
            <param name="confidence"> A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override 'isIdentical' and fine-tune the result on their own data. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.#ctor(System.Boolean,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceVerificationResult" />. </summary>
            <param name="isIdentical"> True if the two faces belong to the same person or the face belongs to the person, otherwise false. </param>
            <param name="confidence"> A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override 'isIdentical' and fine-tune the result on their own data. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FaceVerificationResult" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceVerificationResult.IsIdentical">
            <summary> True if the two faces belong to the same person or the face belongs to the person, otherwise false. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FaceVerificationResult.Confidence">
            <summary> A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override 'isIdentical' and fine-tune the result on their own data. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FacialHair">
            <summary> Properties describing facial hair attributes. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.#ctor(System.Single,System.Single,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FacialHair" />. </summary>
            <param name="moustache"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="beard"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="sideburns"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.#ctor(System.Single,System.Single,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FacialHair" />. </summary>
            <param name="moustache"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="beard"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="sideburns"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FacialHair" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FacialHair.Moustache">
            <summary> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FacialHair.Beard">
            <summary> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FacialHair.Sideburns">
            <summary> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.FindSimilarMatchMode">
            <summary> Similar face searching mode. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FindSimilarMatchMode" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.FindSimilarMatchMode.MatchPerson">
            <summary> Match person. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FindSimilarMatchMode.MatchFace">
            <summary> Match face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.op_Equality(Azure.AI.Vision.Face.FindSimilarMatchMode,Azure.AI.Vision.Face.FindSimilarMatchMode)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FindSimilarMatchMode" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.op_Inequality(Azure.AI.Vision.Face.FindSimilarMatchMode,Azure.AI.Vision.Face.FindSimilarMatchMode)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.FindSimilarMatchMode" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.op_Implicit(System.String)~Azure.AI.Vision.Face.FindSimilarMatchMode">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.FindSimilarMatchMode" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.Equals(Azure.AI.Vision.Face.FindSimilarMatchMode)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarMatchMode.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.FindSimilarRequest">
            <summary> The FindSimilarRequest. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.#ctor(System.Guid,System.Collections.Generic.IEnumerable{System.Guid})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FindSimilarRequest" />. </summary>
            <param name="faceId"> faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
            <param name="faceIds"> An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceIds" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.#ctor(System.Guid,System.Nullable{System.Int32},System.Nullable{Azure.AI.Vision.Face.FindSimilarMatchMode},System.Collections.Generic.IList{System.Guid},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FindSimilarRequest" />. </summary>
            <param name="faceId"> faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </param>
            <param name="maxNumOfCandidatesReturned"> The number of top similar faces returned. The valid range is [1, 1000]. Default value is 20. </param>
            <param name="mode"> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. Default value is 'matchPerson'. </param>
            <param name="faceIds"> An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.FindSimilarRequest" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FindSimilarRequest.FaceId">
            <summary> faceId of the query face. User needs to call "Detect" first to get a valid faceId. Note that this faceId is not persisted and will expire 24 hours after the detection call. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FindSimilarRequest.MaxNumOfCandidatesReturned">
            <summary> The number of top similar faces returned. The valid range is [1, 1000]. Default value is 20. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FindSimilarRequest.Mode">
            <summary> Similar face searching mode. It can be 'matchPerson' or 'matchFace'. Default value is 'matchPerson'. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.FindSimilarRequest.FaceIds">
            <summary> An array of candidate faceIds. All of them are created by "Detect" and the faceIds will expire 24 hours after the detection call. The number of faceIds is limited to 1000. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.GlassesType">
            <summary> Glasses type of the face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.GlassesType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.GlassesType.NoGlasses">
            <summary> No glasses on the face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.GlassesType.ReadingGlasses">
            <summary> Normal glasses on the face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.GlassesType.Sunglasses">
            <summary> Sunglasses on the face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.GlassesType.SwimmingGoggles">
            <summary> Swimming goggles on the face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.op_Equality(Azure.AI.Vision.Face.GlassesType,Azure.AI.Vision.Face.GlassesType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.GlassesType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.op_Inequality(Azure.AI.Vision.Face.GlassesType,Azure.AI.Vision.Face.GlassesType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.GlassesType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.op_Implicit(System.String)~Azure.AI.Vision.Face.GlassesType">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.GlassesType" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.Equals(Azure.AI.Vision.Face.GlassesType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.GlassesType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.GroupRequest">
            <summary> The GroupRequest. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.#ctor(System.Collections.Generic.IEnumerable{System.Guid})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.GroupRequest" />. </summary>
            <param name="faceIds"> Array of candidate faceIds created by "Detect". The maximum is 1000 faces. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceIds" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.#ctor(System.Collections.Generic.IList{System.Guid},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.GroupRequest" />. </summary>
            <param name="faceIds"> Array of candidate faceIds created by "Detect". The maximum is 1000 faces. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.GroupRequest" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.GroupRequest.FaceIds">
            <summary> Array of candidate faceIds created by "Detect". The maximum is 1000 faces. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.HairColor">
            <summary> An array of candidate colors and confidence level in the presence of each. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.#ctor(Azure.AI.Vision.Face.HairColorType,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairColor" />. </summary>
            <param name="color"> Name of the hair color. </param>
            <param name="confidence"> Confidence level of the color. Range between [0,1]. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.#ctor(Azure.AI.Vision.Face.HairColorType,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairColor" />. </summary>
            <param name="color"> Name of the hair color. </param>
            <param name="confidence"> Confidence level of the color. Range between [0,1]. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairColor" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColor.Color">
            <summary> Name of the hair color. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColor.Confidence">
            <summary> Confidence level of the color. Range between [0,1]. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.HairColorType">
            <summary> Name of the hair color. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairColorType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.UnknownHairColor">
            <summary> Unknown. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.White">
            <summary> White. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.Gray">
            <summary> Gray. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.Blond">
            <summary> Blond. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.Brown">
            <summary> Brown. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.Red">
            <summary> Red. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.Black">
            <summary> Black. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairColorType.Other">
            <summary> Other. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.op_Equality(Azure.AI.Vision.Face.HairColorType,Azure.AI.Vision.Face.HairColorType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.HairColorType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.op_Inequality(Azure.AI.Vision.Face.HairColorType,Azure.AI.Vision.Face.HairColorType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.HairColorType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.op_Implicit(System.String)~Azure.AI.Vision.Face.HairColorType">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.HairColorType" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.Equals(Azure.AI.Vision.Face.HairColorType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColorType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.HairProperties">
            <summary> Properties describing hair attributes. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.#ctor(System.Single,System.Boolean,System.Collections.Generic.IEnumerable{Azure.AI.Vision.Face.HairColor})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairProperties" />. </summary>
            <param name="bald"> A number describing confidence level of whether the person is bald. </param>
            <param name="invisible"> A boolean value describing whether the hair is visible in the image. </param>
            <param name="hairColor"> An array of candidate colors and confidence level in the presence of each. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="hairColor" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.#ctor(System.Single,System.Boolean,System.Collections.Generic.IReadOnlyList{Azure.AI.Vision.Face.HairColor},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairProperties" />. </summary>
            <param name="bald"> A number describing confidence level of whether the person is bald. </param>
            <param name="invisible"> A boolean value describing whether the hair is visible in the image. </param>
            <param name="hairColor"> An array of candidate colors and confidence level in the presence of each. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HairProperties" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairProperties.Bald">
            <summary> A number describing confidence level of whether the person is bald. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairProperties.Invisible">
            <summary> A boolean value describing whether the hair is visible in the image. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HairProperties.HairColor">
            <summary> An array of candidate colors and confidence level in the presence of each. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.HeadPose">
            <summary> 3-D roll/yaw/pitch angles for face direction. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.#ctor(System.Single,System.Single,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HeadPose" />. </summary>
            <param name="pitch"> Value of angles. </param>
            <param name="roll"> Value of angles. </param>
            <param name="yaw"> Value of angles. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.#ctor(System.Single,System.Single,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HeadPose" />. </summary>
            <param name="pitch"> Value of angles. </param>
            <param name="roll"> Value of angles. </param>
            <param name="yaw"> Value of angles. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.HeadPose" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HeadPose.Pitch">
            <summary> Value of angles. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HeadPose.Roll">
            <summary> Value of angles. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.HeadPose.Yaw">
            <summary> Value of angles. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LandmarkCoordinate">
            <summary> Landmark coordinates within an image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.#ctor(System.Single,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LandmarkCoordinate" />. </summary>
            <param name="x"> The horizontal component, in pixels. </param>
            <param name="y"> The vertical component, in pixels. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.#ctor(System.Single,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LandmarkCoordinate" />. </summary>
            <param name="x"> The horizontal component, in pixels. </param>
            <param name="y"> The vertical component, in pixels. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LandmarkCoordinate" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LandmarkCoordinate.X">
            <summary> The horizontal component, in pixels. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LandmarkCoordinate.Y">
            <summary> The vertical component, in pixels. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessModel">
            <summary> The model version used for liveness classification. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessModel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessModel.V20200215Preview01">
            <summary> 2020-02-15-preview.01. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessModel.V20211112Preview03">
            <summary> 2021-11-12-preview.03. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessModel.V20221015Preview04">
            <summary> 2022-10-15-preview.04. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessModel.V20230302Preview05">
            <summary> 2023-03-02-preview.05. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.op_Equality(Azure.AI.Vision.Face.LivenessModel,Azure.AI.Vision.Face.LivenessModel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.LivenessModel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.op_Inequality(Azure.AI.Vision.Face.LivenessModel,Azure.AI.Vision.Face.LivenessModel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.LivenessModel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.op_Implicit(System.String)~Azure.AI.Vision.Face.LivenessModel">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.LivenessModel" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.Equals(Azure.AI.Vision.Face.LivenessModel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessModel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessOperationMode">
            <summary> The liveness operation mode to drive the clients end-user experience. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessOperationMode" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessOperationMode.Passive">
            <summary> Utilizes a passive liveness technique that requires no additional actions from the user. Requires normal indoor lighting and high screen brightness for optimal performance. And thus, this mode has a narrow operational envelope and will not be suitable for scenarios that requires the end-users to be in bright lighting conditions. Note: this is the only supported mode for the Mobile (iOS and Android) solution. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessOperationMode.PassiveActive">
            <summary> This mode utilizes a hybrid passive or active liveness technique that necessitates user cooperation. It is optimized to require active motion only under suboptimal lighting conditions. Unlike the passive mode, this mode has no lighting restrictions, and thus offering a broader operational envelope. This mode is preferable on Web based solutions due to the lack of automatic screen brightness control available on browsers which hinders the Passive modes operational envelope on Web based solutions. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.op_Equality(Azure.AI.Vision.Face.LivenessOperationMode,Azure.AI.Vision.Face.LivenessOperationMode)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.LivenessOperationMode" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.op_Inequality(Azure.AI.Vision.Face.LivenessOperationMode,Azure.AI.Vision.Face.LivenessOperationMode)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.LivenessOperationMode" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.op_Implicit(System.String)~Azure.AI.Vision.Face.LivenessOperationMode">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.LivenessOperationMode" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.Equals(Azure.AI.Vision.Face.LivenessOperationMode)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOperationMode.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessOutputsTarget">
            <summary> The liveness classification for target face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.#ctor(Azure.AI.Vision.Face.FaceRectangle,System.String,System.Int32,Azure.AI.Vision.Face.FaceImageType)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessOutputsTarget" />. </summary>
            <param name="faceRectangle"> The face region where the liveness classification was made on. </param>
            <param name="fileName"> The file name which contains the face rectangle where the liveness classification was made on. </param>
            <param name="timeOffsetWithinFile"> The time offset within the file of the frame which contains the face rectangle where the liveness classification was made on. </param>
            <param name="imageType"> The image type which contains the face rectangle where the liveness classification was made on. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceRectangle" /> or <paramref name="fileName" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.#ctor(Azure.AI.Vision.Face.FaceRectangle,System.String,System.Int32,Azure.AI.Vision.Face.FaceImageType,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessOutputsTarget" />. </summary>
            <param name="faceRectangle"> The face region where the liveness classification was made on. </param>
            <param name="fileName"> The file name which contains the face rectangle where the liveness classification was made on. </param>
            <param name="timeOffsetWithinFile"> The time offset within the file of the frame which contains the face rectangle where the liveness classification was made on. </param>
            <param name="imageType"> The image type which contains the face rectangle where the liveness classification was made on. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessOutputsTarget" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessOutputsTarget.FaceRectangle">
            <summary> The face region where the liveness classification was made on. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessOutputsTarget.FileName">
            <summary> The file name which contains the face rectangle where the liveness classification was made on. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessOutputsTarget.TimeOffsetWithinFile">
            <summary> The time offset within the file of the frame which contains the face rectangle where the liveness classification was made on. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessOutputsTarget.ImageType">
            <summary> The image type which contains the face rectangle where the liveness classification was made on. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessResponseBody">
            <summary> The response body of detect liveness API call. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessResponseBody" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.#ctor(System.Nullable{Azure.AI.Vision.Face.FaceLivenessDecision},Azure.AI.Vision.Face.LivenessOutputsTarget,System.Nullable{Azure.AI.Vision.Face.LivenessModel},Azure.AI.Vision.Face.LivenessWithVerifyOutputs,System.Collections.Generic.IReadOnlyDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessResponseBody" />. </summary>
            <param name="livenessDecision"> The liveness classification for the target face. </param>
            <param name="target"> Specific targets used for liveness classification. </param>
            <param name="modelVersionUsed"> The model version used for liveness classification. </param>
            <param name="verifyResult"> The face verification output. Only available when the request is liveness with verify. </param>
            <param name="additionalProperties"> Additional Properties. </param>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessResponseBody.LivenessDecision">
            <summary> The liveness classification for the target face. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessResponseBody.Target">
            <summary> Specific targets used for liveness classification. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessResponseBody.ModelVersionUsed">
            <summary> The model version used for liveness classification. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessResponseBody.VerifyResult">
            <summary> The face verification output. Only available when the request is liveness with verify. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessResponseBody.AdditionalProperties">
            <summary>
            Additional Properties
            <para>
            To assign an object to the value of this property use <see cref="M:System.BinaryData.FromObjectAsJson``1(``0,System.Text.Json.JsonSerializerOptions)" />.
            </para>
            <para>
            To assign an already formatted json string to this property use <see cref="M:System.BinaryData.FromString(System.String)" />.
            </para>
            <para>
            Examples:
            <list type="bullet">
            <item>
            <term>BinaryData.FromObjectAsJson("foo")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromString("\"foo\"")</term>
            <description>Creates a payload of "foo".</description>
            </item>
            <item>
            <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            <item>
            <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
            <description>Creates a payload of { "key": "value" }.</description>
            </item>
            </list>
            </para>
            </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessSession">
            <summary> Session result of detect liveness. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.#ctor(System.DateTimeOffset,System.Boolean,Azure.AI.Vision.Face.FaceSessionStatus)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSession" />. </summary>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="status"> The current status of the session. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.#ctor(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Boolean,System.String,System.Nullable{System.Int32},Azure.AI.Vision.Face.FaceSessionStatus,Azure.AI.Vision.Face.LivenessSessionAuditEntry,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSession" />. </summary>
            <param name="id"> The unique ID to reference this session. </param>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionStartDateTime"> DateTime when this session was started by the client. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <param name="status"> The current status of the session. </param>
            <param name="result"> The latest session audit result only populated if status == 'ResultAvailable'. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSession" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.Id">
            <summary> The unique ID to reference this session. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.CreatedDateTime">
            <summary> DateTime when this session was created. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.SessionStartDateTime">
            <summary> DateTime when this session was started by the client. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.SessionExpired">
            <summary> Whether or not the session is expired. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.DeviceCorrelationId">
            <summary> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.AuthTokenTimeToLiveInSeconds">
            <summary> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.Status">
            <summary> The current status of the session. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSession.Result">
            <summary> The latest session audit result only populated if status == 'ResultAvailable'. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessSessionAuditEntry">
            <summary> Audit entry for a request in session. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.#ctor(System.Int64,System.String,System.String,System.String,System.DateTimeOffset,Azure.AI.Vision.Face.AuditRequestInfo,Azure.AI.Vision.Face.AuditLivenessResponseInfo,System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionAuditEntry" />. </summary>
            <param name="id"> The unique id to refer to this audit request. Use this id with the 'start' query parameter to continue on to the next page of audit results. </param>
            <param name="sessionId"> The unique sessionId of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding session DELETE operation. </param>
            <param name="requestId"> The unique requestId that is returned by the service to the client in the 'apim-request-id' header. </param>
            <param name="clientRequestId"> The unique clientRequestId that is sent by the client in the 'client-request-id' header. </param>
            <param name="receivedDateTime"> The UTC DateTime that the request was received. </param>
            <param name="request"> The request of this entry. </param>
            <param name="response"> The response of this entry. </param>
            <param name="digest"> The server calculated digest for this request. If the client reported digest differs from the server calculated digest, then the message integrity between the client and service has been compromised and the result should not be trusted. For more information, see how to guides on how to leverage this value to secure your end-to-end solution. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="sessionId" />, <paramref name="requestId" />, <paramref name="clientRequestId" />, <paramref name="request" />, <paramref name="response" /> or <paramref name="digest" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.#ctor(System.Int64,System.String,System.String,System.String,System.DateTimeOffset,Azure.AI.Vision.Face.AuditRequestInfo,Azure.AI.Vision.Face.AuditLivenessResponseInfo,System.String,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionAuditEntry" />. </summary>
            <param name="id"> The unique id to refer to this audit request. Use this id with the 'start' query parameter to continue on to the next page of audit results. </param>
            <param name="sessionId"> The unique sessionId of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding session DELETE operation. </param>
            <param name="requestId"> The unique requestId that is returned by the service to the client in the 'apim-request-id' header. </param>
            <param name="clientRequestId"> The unique clientRequestId that is sent by the client in the 'client-request-id' header. </param>
            <param name="receivedDateTime"> The UTC DateTime that the request was received. </param>
            <param name="request"> The request of this entry. </param>
            <param name="response"> The response of this entry. </param>
            <param name="digest"> The server calculated digest for this request. If the client reported digest differs from the server calculated digest, then the message integrity between the client and service has been compromised and the result should not be trusted. For more information, see how to guides on how to leverage this value to secure your end-to-end solution. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionAuditEntry" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.Id">
            <summary> The unique id to refer to this audit request. Use this id with the 'start' query parameter to continue on to the next page of audit results. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.SessionId">
            <summary> The unique sessionId of the created session. It will expire 48 hours after it was created or may be deleted sooner using the corresponding session DELETE operation. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.RequestId">
            <summary> The unique requestId that is returned by the service to the client in the 'apim-request-id' header. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.ClientRequestId">
            <summary> The unique clientRequestId that is sent by the client in the 'client-request-id' header. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.ReceivedDateTime">
            <summary> The UTC DateTime that the request was received. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.Request">
            <summary> The request of this entry. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.Response">
            <summary> The response of this entry. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionAuditEntry.Digest">
            <summary> The server calculated digest for this request. If the client reported digest differs from the server calculated digest, then the message integrity between the client and service has been compromised and the result should not be trusted. For more information, see how to guides on how to leverage this value to secure your end-to-end solution. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessSessionItem">
            <summary> Session data returned for enumeration. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.#ctor(System.DateTimeOffset,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionItem" />. </summary>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.#ctor(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Boolean,System.String,System.Nullable{System.Int32},System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionItem" />. </summary>
            <param name="id"> The unique ID to reference this session. </param>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionStartDateTime"> DateTime when this session was started by the client. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessSessionItem" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionItem.Id">
            <summary> The unique ID to reference this session. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionItem.CreatedDateTime">
            <summary> DateTime when this session was created. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionItem.SessionStartDateTime">
            <summary> DateTime when this session was started by the client. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionItem.SessionExpired">
            <summary> Whether or not the session is expired. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionItem.DeviceCorrelationId">
            <summary> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessSessionItem.AuthTokenTimeToLiveInSeconds">
            <summary> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessWithVerifyImage">
            <summary> The detail of face for verification. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.#ctor(Azure.AI.Vision.Face.FaceRectangle,Azure.AI.Vision.Face.QualityForRecognition)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyImage" />. </summary>
            <param name="faceRectangle"> The face region where the comparison image's classification was made. </param>
            <param name="qualityForRecognition"> Quality of face image for recognition. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="faceRectangle" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.#ctor(Azure.AI.Vision.Face.FaceRectangle,Azure.AI.Vision.Face.QualityForRecognition,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyImage" />. </summary>
            <param name="faceRectangle"> The face region where the comparison image's classification was made. </param>
            <param name="qualityForRecognition"> Quality of face image for recognition. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyImage" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifyImage.FaceRectangle">
            <summary> The face region where the comparison image's classification was made. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifyImage.QualityForRecognition">
            <summary> Quality of face image for recognition. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessWithVerifyOutputs">
            <summary> The face verification output. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.#ctor(Azure.AI.Vision.Face.LivenessWithVerifyImage,System.Single,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyOutputs" />. </summary>
            <param name="verifyImage"> The detail of face for verification. </param>
            <param name="matchConfidence"> The target face liveness face and comparison image face verification confidence. </param>
            <param name="isIdentical"> Whether the target liveness face and comparison image face match. </param>
            <exception cref="T:System.ArgumentNullException"> <paramref name="verifyImage" /> is null. </exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.#ctor(Azure.AI.Vision.Face.LivenessWithVerifyImage,System.Single,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyOutputs" />. </summary>
            <param name="verifyImage"> The detail of face for verification. </param>
            <param name="matchConfidence"> The target face liveness face and comparison image face verification confidence. </param>
            <param name="isIdentical"> Whether the target liveness face and comparison image face match. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifyOutputs" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.VerifyImage">
            <summary> The detail of face for verification. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.MatchConfidence">
            <summary> The target face liveness face and comparison image face verification confidence. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.IsIdentical">
            <summary> Whether the target liveness face and comparison image face match. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.LivenessWithVerifySession">
            <summary> Session result of detect liveness with verify. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.#ctor(System.DateTimeOffset,System.Boolean,Azure.AI.Vision.Face.FaceSessionStatus)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifySession" />. </summary>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="status"> The current status of the session. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.#ctor(System.String,System.DateTimeOffset,System.Nullable{System.DateTimeOffset},System.Boolean,System.String,System.Nullable{System.Int32},Azure.AI.Vision.Face.FaceSessionStatus,Azure.AI.Vision.Face.LivenessSessionAuditEntry,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifySession" />. </summary>
            <param name="id"> The unique ID to reference this session. </param>
            <param name="createdDateTime"> DateTime when this session was created. </param>
            <param name="sessionStartDateTime"> DateTime when this session was started by the client. </param>
            <param name="sessionExpired"> Whether or not the session is expired. </param>
            <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
            <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
            <param name="status"> The current status of the session. </param>
            <param name="result"> The latest session audit result only populated if status == 'ResultAvailable'. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.LivenessWithVerifySession" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.Id">
            <summary> The unique ID to reference this session. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.CreatedDateTime">
            <summary> DateTime when this session was created. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.SessionStartDateTime">
            <summary> DateTime when this session was started by the client. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.SessionExpired">
            <summary> Whether or not the session is expired. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.DeviceCorrelationId">
            <summary> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.AuthTokenTimeToLiveInSeconds">
            <summary> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.Status">
            <summary> The current status of the session. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.LivenessWithVerifySession.Result">
            <summary> The latest session audit result only populated if status == 'ResultAvailable'. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.MaskProperties">
            <summary> Properties describing the presence of a mask on a given face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.#ctor(System.Boolean,Azure.AI.Vision.Face.MaskType)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.MaskProperties" />. </summary>
            <param name="noseAndMouthCovered"> A boolean value indicating whether nose and mouth are covered. </param>
            <param name="type"> Type of the mask. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.#ctor(System.Boolean,Azure.AI.Vision.Face.MaskType,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.MaskProperties" />. </summary>
            <param name="noseAndMouthCovered"> A boolean value indicating whether nose and mouth are covered. </param>
            <param name="type"> Type of the mask. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.MaskProperties" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.MaskProperties.NoseAndMouthCovered">
            <summary> A boolean value indicating whether nose and mouth are covered. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.MaskProperties.Type">
            <summary> Type of the mask. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.MaskType">
            <summary> Type of the mask. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.MaskType" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.MaskType.FaceMask">
            <summary> Face mask. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.MaskType.NoMask">
            <summary> No mask. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.MaskType.OtherMaskOrOcclusion">
            <summary> Other types of mask or occlusion. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.MaskType.Uncertain">
            <summary> Uncertain. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.op_Equality(Azure.AI.Vision.Face.MaskType,Azure.AI.Vision.Face.MaskType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.MaskType" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.op_Inequality(Azure.AI.Vision.Face.MaskType,Azure.AI.Vision.Face.MaskType)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.MaskType" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.op_Implicit(System.String)~Azure.AI.Vision.Face.MaskType">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.MaskType" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.Equals(Azure.AI.Vision.Face.MaskType)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskType.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.NoiseLevel">
            <summary> Indicates level of noise. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.NoiseLevel" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.NoiseLevel.Low">
            <summary> Low noise level. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.NoiseLevel.Medium">
            <summary> Medium noise level. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.NoiseLevel.High">
            <summary> High noise level. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.op_Equality(Azure.AI.Vision.Face.NoiseLevel,Azure.AI.Vision.Face.NoiseLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.NoiseLevel" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.op_Inequality(Azure.AI.Vision.Face.NoiseLevel,Azure.AI.Vision.Face.NoiseLevel)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.NoiseLevel" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.op_Implicit(System.String)~Azure.AI.Vision.Face.NoiseLevel">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.NoiseLevel" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.Equals(Azure.AI.Vision.Face.NoiseLevel)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseLevel.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.NoiseProperties">
            <summary> Properties describing noise level of the image. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.#ctor(Azure.AI.Vision.Face.NoiseLevel,System.Single)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.NoiseProperties" />. </summary>
            <param name="noiseLevel"> An enum value indicating level of noise. </param>
            <param name="value"> A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.#ctor(Azure.AI.Vision.Face.NoiseLevel,System.Single,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.NoiseProperties" />. </summary>
            <param name="noiseLevel"> An enum value indicating level of noise. </param>
            <param name="value"> A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.NoiseProperties" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.NoiseProperties.NoiseLevel">
            <summary> An enum value indicating level of noise. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.NoiseProperties.Value">
            <summary> A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.OcclusionProperties">
            <summary> Properties describing occlusions on a given face. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.#ctor(System.Boolean,System.Boolean,System.Boolean)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.OcclusionProperties" />. </summary>
            <param name="foreheadOccluded"> A boolean value indicating whether forehead is occluded. </param>
            <param name="eyeOccluded"> A boolean value indicating whether eyes are occluded. </param>
            <param name="mouthOccluded"> A boolean value indicating whether the mouth is occluded. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.#ctor(System.Boolean,System.Boolean,System.Boolean,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.OcclusionProperties" />. </summary>
            <param name="foreheadOccluded"> A boolean value indicating whether forehead is occluded. </param>
            <param name="eyeOccluded"> A boolean value indicating whether eyes are occluded. </param>
            <param name="mouthOccluded"> A boolean value indicating whether the mouth is occluded. </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.OcclusionProperties" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.OcclusionProperties.ForeheadOccluded">
            <summary> A boolean value indicating whether forehead is occluded. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.OcclusionProperties.EyeOccluded">
            <summary> A boolean value indicating whether eyes are occluded. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.OcclusionProperties.MouthOccluded">
            <summary> A boolean value indicating whether the mouth is occluded. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.AI.Vision.Face.QualityForRecognition">
            <summary> Indicates quality of image for recognition. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.#ctor(System.String)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.QualityForRecognition" />. </summary>
            <exception cref="T:System.ArgumentNullException"> <paramref name="value" /> is null. </exception>
        </member>
        <member name="P:Azure.AI.Vision.Face.QualityForRecognition.Low">
            <summary> Low quality. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.QualityForRecognition.Medium">
            <summary> Medium quality. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.QualityForRecognition.High">
            <summary> High quality. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.op_Equality(Azure.AI.Vision.Face.QualityForRecognition,Azure.AI.Vision.Face.QualityForRecognition)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.QualityForRecognition" /> values are the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.op_Inequality(Azure.AI.Vision.Face.QualityForRecognition,Azure.AI.Vision.Face.QualityForRecognition)">
            <summary> Determines if two <see cref="T:Azure.AI.Vision.Face.QualityForRecognition" /> values are not the same. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.op_Implicit(System.String)~Azure.AI.Vision.Face.QualityForRecognition">
            <summary> Converts a string to a <see cref="T:Azure.AI.Vision.Face.QualityForRecognition" />. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.Equals(System.Object)">
            <summary>Indicates whether this instance and a specified object are equal.</summary><param name="obj">The object to compare with the current instance.</param><returns><see langword="true" /> if <paramref name="obj" /> and this instance are the same type and represent the same value; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.Equals(Azure.AI.Vision.Face.QualityForRecognition)">
            <summary>Indicates whether the current object is equal to another object of the same type.</summary><param name="other">An object to compare with this object.</param><returns><see langword="true" /> if the current object is equal to the <paramref name="other" /> parameter; otherwise, <see langword="false" />.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.GetHashCode">
            <summary>Returns the hash code for this instance.</summary><returns>A 32-bit signed integer that is the hash code for this instance.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.QualityForRecognition.ToString">
            <summary>Returns the fully qualified type name of this instance.</summary><returns>The fully qualified type name.</returns>
        </member>
        <member name="T:Azure.AI.Vision.Face.VerifyFaceToFaceRequest">
            <summary> The VerifyFaceToFaceRequest. </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.#ctor(System.Guid,System.Guid)">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.VerifyFaceToFaceRequest" />. </summary>
            <param name="faceId1"> The faceId of one face, come from "Detect". </param>
            <param name="faceId2"> The faceId of another face, come from "Detect". </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.#ctor(System.Guid,System.Guid,System.Collections.Generic.IDictionary{System.String,System.BinaryData})">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.VerifyFaceToFaceRequest" />. </summary>
            <param name="faceId1"> The faceId of one face, come from "Detect". </param>
            <param name="faceId2"> The faceId of another face, come from "Detect". </param>
            <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.#ctor">
            <summary> Initializes a new instance of <see cref="T:Azure.AI.Vision.Face.VerifyFaceToFaceRequest" /> for deserialization. </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.FaceId1">
            <summary> The faceId of one face, come from "Detect". </summary>
        </member>
        <member name="P:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.FaceId2">
            <summary> The faceId of another face, come from "Detect". </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.FromResponse(Azure.Response)">
            <summary> Deserializes the model from a raw response. </summary>
            <param name="response"> The response to deserialize the model from. </param>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.ToRequestContent">
            <summary> Convert into a <see cref="T:Azure.Core.RequestContent" />. </summary>
        </member>
        <member name="T:Azure.Core.AzureResourceProviderNamespaceAttribute">
            <summary>
            This attribute should be set on all client assemblies with value of one of the resource providers
            from the https://docs.microsoft.com/azure/azure-resource-manager/management/azure-services-resource-providers list.
            </summary>
        </member>
        <member name="M:Azure.Core.AzureKeyCredentialPolicy.#ctor(Azure.AzureKeyCredential,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.AzureKeyCredentialPolicy" /> class.
            </summary>
            <param name="credential">The <see cref="T:Azure.AzureKeyCredential" /> used to authenticate requests.</param>
            <param name="name">The name of the key header used for the credential.</param>
            <param name="prefix">The prefix to apply before the credential key. For example, a prefix of "SharedAccessKey" would result in
            a value of "SharedAccessKey {credential.Key}" being stamped on the request header with header key of <paramref name="name" />.</param>
        </member>
        <member name="M:Azure.Core.AzureKeyCredentialPolicy.OnSendingRequest(Azure.Core.HttpMessage)">
            <summary>
            Method is invoked before the request is sent.
            </summary><param name="message">The <see cref="T:Azure.Core.HttpMessage" /> containing the request.</param>
        </member>
        <member name="T:Azure.Core.ForwardsClientCallsAttribute">
            <summary>
            Marks methods that call methods on other client and don't need their diagnostics verified.
            </summary>
        </member>
        <member name="M:Azure.Core.ForwardsClientCallsAttribute.#ctor">
            <summary>
            Creates a new instance of <see cref="T:Azure.Core.ForwardsClientCallsAttribute" />.
            </summary>
        </member>
        <member name="M:Azure.Core.ForwardsClientCallsAttribute.#ctor(System.Boolean)">
            <summary>
            Creates a new instance of <see cref="T:Azure.Core.ForwardsClientCallsAttribute" />.
            </summary>
            <param name="skipChecks"> Sets whether or not diagnostic scope validation should happen. </param>
        </member>
        <member name="P:Azure.Core.ForwardsClientCallsAttribute.SkipChecks">
            <summary>
            Gets whether or not we should validate DiagnosticScope for this API.
            In the case where there is an internal API that makes the Azure API call and a public API that uses it we need ForwardsClientCalls.
            If the public API will cache the results then the diagnostic scope will not always be created because an Azure API is not always called.
            In this case we need to turn off this validation for this API only.
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenModelAttribute.Usage">
            <summary>
            Gets or sets a coma separated list of additional model usage modes. Allowed values: model, error, intput, output.
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenModelAttribute.Formats">
            <summary>
            Gets or sets a coma separated list of additional model serialization formats.
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.PropertyName">
            <summary>
            Gets or sets the property name which these hooks should apply to
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.SerializationPath">
            <summary>
            Gets or sets the serialization path of the property in the JSON
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.SerializationValueHook">
            <summary>
            Gets or sets the method name to use when serializing the property value (property name excluded)
            The signature of the serialization hook method must be or compatible with when invoking:
            private void SerializeHook(Utf8JsonWriter writer);
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.DeserializationValueHook">
            <summary>
            Gets or sets the method name to use when deserializing the property value from the JSON
            private static void DeserializationHook(JsonProperty property, ref TypeOfTheProperty propertyValue); // if the property is required
            private static void DeserializationHook(JsonProperty property, ref Optional&lt;TypeOfTheProperty&gt; propertyValue); // if the property is optional
            </summary>
        </member>
        <member name="P:Azure.Core.CodeGenSerializationAttribute.BicepSerializationValueHook">
            <summary>
            Gets or sets the method name to use when serializing the property value (property name excluded)
            The signature of the serialization hook method must be or compatible with when invoking:
            private void SerializeHook(StringBuilder builder);
            </summary>
        </member>
        <member name="T:Azure.Core.AppContextSwitchHelper">
            <summary>
            Helper for interacting with AppConfig settings and their related Environment variable settings.
            </summary>
        </member>
        <member name="M:Azure.Core.AppContextSwitchHelper.GetConfigValue(System.String,System.String)">
            <summary>
            Determines if either an AppContext switch or its corresponding Environment Variable is set
            </summary>
            <param name="appContexSwitchName">Name of the AppContext switch.</param>
            <param name="environmentVariableName">Name of the Environment variable.</param>
            <returns>If the AppContext switch has been set, returns the value of the switch.
            If the AppContext switch has not been set, returns the value of the environment variable.
            False if neither is set.
            </returns>
        </member>
        <member name="T:Azure.Core.AsyncLockWithValue`1">
            <summary>
            Primitive that combines async lock and value cache
            </summary>
            <typeparam name="T"></typeparam>
        </member>
        <member name="M:Azure.Core.AsyncLockWithValue`1.GetLockOrValueAsync(System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Method that either returns cached value or acquire a lock.
            If one caller has acquired a lock, other callers will be waiting for the lock to be released.
            If value is set, lock is released and all waiters get that value.
            If value isn't set, the next waiter in the queue will get the lock.
            </summary>
            <param name="async"></param>
            <param name="cancellationToken"></param>
            <returns></returns>
        </member>
        <member name="P:Azure.Core.AsyncLockWithValue`1.LockOrValue.HasValue">
            <summary>
            Returns true if lock contains the cached value. Otherwise false.
            </summary>
        </member>
        <member name="P:Azure.Core.AsyncLockWithValue`1.LockOrValue.Value">
            <summary>
            Returns cached value if it was set when lock has been created. Throws exception otherwise.
            </summary>
            <exception cref="T:System.InvalidOperationException">Value isn't set.</exception>
        </member>
        <member name="M:Azure.Core.AsyncLockWithValue`1.LockOrValue.SetValue(`0)">
            <summary>
            Set value to the cache and to all the waiters.
            </summary>
            <param name="value"></param>
            <exception cref="T:System.InvalidOperationException">Value is set already.</exception>
        </member>
        <member name="M:Azure.Core.Pipeline.ClientDiagnostics.#ctor(Azure.Core.ClientOptions,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> class.
            </summary>
            <param name="options">The customer provided client options object.</param>
            <param name="suppressNestedClientActivities">Flag controlling if <see cref="T:System.Diagnostics.Activity" />
             created by this <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> for client method calls should be suppressed when called
             by other Azure SDK client methods.  It's recommended to set it to true for new clients; use default (null)
             for backward compatibility reasons, or set it to false to explicitly disable suppression for specific cases.
             The default value could change in the future, the flag should be only set to false if suppression for the client
             should never be enabled.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.ClientDiagnostics.#ctor(System.String,System.String,Azure.Core.DiagnosticsOptions,System.Nullable{System.Boolean})">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> class.
            </summary>
            <param name="optionsNamespace">Namespace of the client class, such as Azure.Storage or Azure.AppConfiguration.</param>
            <param name="providerNamespace">Azure Resource Provider namespace of the Azure service SDK is primarily used for.</param>
            <param name="diagnosticsOptions">The customer provided client diagnostics options.</param>
            <param name="suppressNestedClientActivities">Flag controlling if <see cref="T:System.Diagnostics.Activity" />
             created by this <see cref="T:Azure.Core.Pipeline.ClientDiagnostics" /> for client method calls should be suppressed when called
             by other Azure SDK client methods.  It's recommended to set it to true for new clients, use default (null) for old clients
             for backward compatibility reasons, or set it to false to explicitly disable suppression for specific cases.
             The default value could change in the future, the flag should be only set to false if suppression for the client
             should never be enabled.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.AddLink(System.String,System.String,System.Collections.Generic.IDictionary{System.String,System.Object})">
            <summary>
            Adds a link to the scope. This must be called before <see cref="M:Azure.Core.Pipeline.DiagnosticScope.Start" /> has been called for the DiagnosticScope.
            </summary>
            <param name="traceparent">The traceparent for the link.</param>
            <param name="tracestate">The tracestate for the link.</param>
            <param name="attributes">Optional attributes to associate with the link.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.SetTraceContext(System.String,System.String)">
            <summary>
            Sets the trace context for the current scope.
            </summary>
            <param name="traceparent">The trace parent to set for the current scope.</param>
            <param name="tracestate">The trace state to set for the current scope.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.Failed(System.Exception)">
            <summary>
            Marks the scope as failed.
            </summary>
            <param name="exception">The exception to associate with the failed scope.</param>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScope.Failed(System.String)">
            <summary>
            Marks the scope as failed with low-cardinality error.type attribute.
            </summary>
            <param name="errorCode">Error code to associate with the failed scope.</param>
        </member>
        <member name="T:Azure.Core.Pipeline.ActivityExtensions">
            <summary>
            Until Activity Source is no longer considered experimental.
            </summary>
        </member>
        <member name="M:Azure.Core.Pipeline.DiagnosticScopeFactory.#ctor(System.String,System.String,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Creates diagnostic scope factory.
            </summary>
            <param name="clientNamespace">The namespace which is used as a prefix for all ActivitySources created by the factory and the name of DiagnosticSource (when used).</param>
            <param name="resourceProviderNamespace">Azure resource provider namespace.</param>
            <param name="isActivityEnabled">Flag indicating if distributed tracing is enabled.</param>
            <param name="suppressNestedClientActivities">Flag indicating if nested Azure SDK activities describing public API calls should be suppressed.</param>
            <param name="isStable">Whether instrumentation is considered stable. When false, experimental feature flag controls if tracing is enabled.</param>
        </member>
        <member name="T:Azure.Core.Pipeline.TaskExtensions.Enumerable`1">
            <summary>
            Both <see cref="T:Azure.Core.Pipeline.TaskExtensions.Enumerable`1" /> and <see cref="T:Azure.Core.Pipeline.TaskExtensions.Enumerator`1" /> are defined as public structs so that foreach can use duck typing
            to call <see cref="M:Azure.Core.Pipeline.TaskExtensions.Enumerable`1.GetEnumerator" /> and avoid heap memory allocation.
            Please don't delete this method and don't make these types private.
            </summary>
            <typeparam name="T"></typeparam>
        </member>
        <member name="T:Azure.Core.FixedDelayWithNoJitterStrategy">
            <summary>
            A delay strategy that uses a fixed delay with no jitter applied. This is used by data plane LROs.
            </summary>
        </member>
        <member name="T:Azure.Core.OperationInternal">
            <summary>
            A helper class used to build long-running operation instances. In order to use this helper:
            <list type="number">
              <item>Make sure your LRO implements the <see cref="T:Azure.Core.IOperation" /> interface.</item>
              <item>Add a private <see cref="T:Azure.Core.OperationInternal" /> field to your LRO, and instantiate it during construction.</item>
              <item>Delegate method calls to the <see cref="T:Azure.Core.OperationInternal" /> implementations.</item>
            </list>
            Supported members:
            <list type="bullet">
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.HasCompleted" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.RawResponse" />, used for <see cref="M:Azure.Operation.GetRawResponse" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.TimeSpan,System.Threading.CancellationToken)" /></description>
              </item>
            </list>
            </summary>
        </member>
        <member name="M:Azure.Core.OperationInternal.Succeeded(Azure.Response)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final successful state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal.Failed(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final failed state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
            <param name="operationFailedException">The exception that will be thrown by <c>UpdateStatusAsync</c>.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal.#ctor(Azure.Core.IOperation,Azure.Core.Pipeline.ClientDiagnostics,Azure.Response,System.String,System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Azure.Core.DelayStrategy)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class.
            </summary>
            <param name="operation">The long-running operation making use of this class. Passing "<c>this</c>" is expected.</param>
            <param name="clientDiagnostics">Used for diagnostic scope and exception creation. This is expected to be the instance created during the construction of your main client.</param>
            <param name="rawResponse">
                The initial value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />. Usually, long-running operation objects can be instantiated in two ways:
                <list type="bullet">
                    <item>
                        When calling a client's "<c>Start&lt;OperationName&gt;</c>" method, a service call is made to start the operation, and an <see cref="T:Azure.Operation" /> instance is returned.
                        In this case, the response received from this service call can be passed here.
                    </item>
                    <item>
                        When a user instantiates an <see cref="T:Azure.Operation" /> directly using a public constructor, there's no previous service call. In this case, passing <c>null</c> is expected.
                    </item>
                </list>
            </param>
            <param name="operationTypeName">
                The type name of the long-running operation making use of this class. Used when creating diagnostic scopes. If left <c>null</c>, the type name will be inferred based on the
                parameter <paramref name="operation" />.
            </param>
            <param name="scopeAttributes">The attributes to use during diagnostic scope creation.</param>
            <param name="fallbackStrategy"> The delay strategy to use. Default is <see cref="T:Azure.Core.FixedDelayWithNoJitterStrategy" />.</param>
        </member>
        <member name="T:Azure.Core.IOperation">
            <summary>
            An interface used by <see cref="T:Azure.Core.OperationInternal" /> for making service calls and updating state. It's expected that
            your long-running operation classes implement this interface.
            </summary>
        </member>
        <member name="M:Azure.Core.IOperation.UpdateStateAsync(System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Calls the service and updates the state of the long-running operation. Properties directly handled by the
            <see cref="T:Azure.Core.OperationInternal" /> class, such as <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />
            don't need to be updated. Operation-specific properties, such as "<c>CreateOn</c>" or "<c>LastModified</c>",
            must be manually updated by the operation implementing this method.
            <example>Usage example:
            <code>
              async ValueTask&lt;OperationState&gt; IOperation.UpdateStateAsync(bool async, CancellationToken cancellationToken)<br />
              {<br />
                Response&lt;R&gt; response = async ? &lt;async service call&gt; : &lt;sync service call&gt;;<br />
                if (&lt;operation succeeded&gt;) return OperationState.Success(response.GetRawResponse(), &lt;parse response&gt;);<br />
                if (&lt;operation failed&gt;) return OperationState.Failure(response.GetRawResponse());<br />
                return OperationState.Pending(response.GetRawResponse());<br />
              }
            </code>
            </example>
            </summary>
            <param name="async"><c>true</c> if the call should be executed asynchronously. Otherwise, <c>false</c>.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>
            A structure indicating the current operation state. The <see cref="T:Azure.Core.OperationState" /> structure must be instantiated by one of
            its static methods:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState.Success(Azure.Response)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </returns>
        </member>
        <member name="T:Azure.Core.OperationState">
            <summary>
            A helper structure passed to <see cref="T:Azure.Core.OperationInternal" /> to indicate the current operation state. This structure must be
            instantiated by one of its static methods, depending on the operation state:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState.Success(Azure.Response)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </summary>
        </member>
        <member name="M:Azure.Core.OperationState.Success(Azure.Response)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState" /> indicating the operation has completed successfully.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState.Failure(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState" /> indicating the operation has completed with failures.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <param name="operationFailedException">
            The exception to throw from <c>UpdateStatus</c> because of the operation failure. If left <c>null</c>,
            a default exception is created based on the <paramref name="rawResponse" /> parameter.
            </param>
            <returns>A new <see cref="T:Azure.Core.OperationState" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState.Pending(Azure.Response)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState" /> indicating the operation has not completed yet.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="P:Azure.Core.OperationInternalBase.RawResponse">
            <summary>
            The last HTTP response received from the server. Its update already handled in calls to "<c>UpdateStatus</c>" and
            "<c>WaitForCompletionAsync</c>", but custom methods not supported by this class, such as "<c>CancelOperation</c>",
            must update it as well.
            <example>Usage example:
            <code>
              public Response GetRawResponse() =&gt; _operationInternal.RawResponse;
            </code>
            </example>
            </summary>
        </member>
        <member name="P:Azure.Core.OperationInternalBase.HasCompleted">
            <summary>
            Returns <c>true</c> if the long-running operation has completed.
            <example>Usage example:
            <code>
              public bool HasCompleted =&gt; _operationInternal.HasCompleted;
            </code>
            </example>
            </summary>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get the latest status of the long-running operation, handling diagnostic scope creation for distributed
            tracing. The default scope name can be changed with the "<c>operationTypeName</c>" parameter passed to the constructor.
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&gt; UpdateStatusAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.UpdateStatusAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The HTTP response received from the server.</returns>
            <remarks>
            After a successful run, this method will update <see cref="P:Azure.Core.OperationInternalBase.RawResponse" /> and might update <see cref="P:Azure.Core.OperationInternalBase.HasCompleted" />.
            </remarks>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get the latest status of the long-running operation, handling diagnostic scope creation for distributed
            tracing. The default scope name can be changed with the "<c>operationTypeName</c>" parameter passed to the constructor.
            <example>Usage example:
            <code>
              public Response UpdateStatus(CancellationToken cancellationToken) =&gt; _operationInternal.UpdateStatus(cancellationToken);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The HTTP response received from the server.</returns>
            <remarks>
            After a successful run, this method will update <see cref="P:Azure.Core.OperationInternalBase.RawResponse" /> and might update <see cref="P:Azure.Core.OperationInternalBase.HasCompleted" />.
            </remarks>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.  The maximum of the retry after value and the fallback strategy
            is then used as the wait interval.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponseAsync(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the parameter <paramref name="pollingInterval" />, but it can change based on information returned
            from the server. After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed. In this case, the maximum value between the <paramref name="pollingInterval" />
            parameter and the retry-after header is chosen as the wait interval. Headers supported are: "Retry-After", "retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server. <strong></strong></param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponse(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.  The maximum of the retry after value and the fallback strategy
            is then used as the wait interval.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternalBase.WaitForCompletionResponse(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the parameter <paramref name="pollingInterval" />, but it can change based on information returned
            from the server. After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed. In this case, the maximum value between the <paramref name="pollingInterval" />
            parameter and the retry-after header is chosen as the wait interval. Headers supported are: "Retry-After", "retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="T:Azure.Core.OperationInternal`1">
            <summary>
            A helper class used to build long-running operation instances. In order to use this helper:
            <list type="number">
              <item>Make sure your LRO implements the <see cref="T:Azure.Core.IOperation`1" /> interface.</item>
              <item>Add a private <see cref="T:Azure.Core.OperationInternal`1" /> field to your LRO, and instantiate it during construction.</item>
              <item>Delegate method calls to the <see cref="T:Azure.Core.OperationInternal`1" /> implementations.</item>
            </list>
            Supported members:
            <list type="bullet">
              <item>
                <description><see cref="P:Azure.Core.OperationInternal`1.HasValue" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.HasCompleted" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternal`1.Value" /></description>
              </item>
              <item>
                <description><see cref="P:Azure.Core.OperationInternalBase.RawResponse" />, used for <see cref="M:Azure.Operation.GetRawResponse" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.Threading.CancellationToken)" /></description>
              </item>
              <item>
                <description><see cref="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.TimeSpan,System.Threading.CancellationToken)" /></description>
              </item>
            </list>
            </summary>
            <typeparam name="T">The final result of the long-running operation. Must match the type used in <see cref="T:Azure.Operation`1" />.</typeparam>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.Succeeded(Azure.Response,`0)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final successful state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
            <param name="value">The final result of the long-running operation.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.Failed(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal" /> class in a final failed state.
            </summary>
            <param name="rawResponse">The final value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />.</param>
            <param name="operationFailedException">The exception that will be thrown by <c>UpdateStatusAsync</c>.</param>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.#ctor(Azure.Core.IOperation{`0},Azure.Core.Pipeline.ClientDiagnostics,Azure.Response,System.String,System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.String}},Azure.Core.DelayStrategy)">
            <summary>
            Initializes a new instance of the <see cref="T:Azure.Core.OperationInternal`1" /> class.
            </summary>
            <param name="operation">The long-running operation making use of this class. Passing "<c>this</c>" is expected.</param>
            <param name="clientDiagnostics">Used for diagnostic scope and exception creation. This is expected to be the instance created during the construction of your main client.</param>
            <param name="rawResponse">
                The initial value of <see cref="P:Azure.Core.OperationInternalBase.RawResponse" />. Usually, long-running operation objects can be instantiated in two ways:
                <list type="bullet">
                    <item>
                        When calling a client's "<c>Start&lt;OperationName&gt;</c>" method, a service call is made to start the operation, and an <see cref="T:Azure.Operation`1" /> instance is returned.
                        In this case, the response received from this service call can be passed here.
                    </item>
                    <item>
                        When a user instantiates an <see cref="T:Azure.Operation`1" /> directly using a public constructor, there's no previous service call. In this case, passing <c>null</c> is expected.
                    </item>
                </list>
            </param>
            <param name="operationTypeName">
                The type name of the long-running operation making use of this class. Used when creating diagnostic scopes. If left <c>null</c>, the type name will be inferred based on the
                parameter <paramref name="operation" />.
            </param>
            <param name="scopeAttributes">The attributes to use during diagnostic scope creation.</param>
            <param name="fallbackStrategy">The delay strategy when Retry-After header is not present.  When it is present, the longer of the two delays will be used.
                Default is <see cref="T:Azure.Core.FixedDelayWithNoJitterStrategy" />.</param>
        </member>
        <member name="P:Azure.Core.OperationInternal`1.HasValue">
            <summary>
            Returns <c>true</c> if the long-running operation completed successfully and has produced a final result.
            <example>Usage example:
            <code>
              public bool HasValue =&gt; _operationInternal.HasValue;
            </code>
            </example>
            </summary>
        </member>
        <member name="P:Azure.Core.OperationInternal`1.Value">
            <summary>
            The final result of the long-running operation.
            <example>Usage example:
            <code>
              public T Value =&gt; _operationInternal.Value;
            </code>
            </example>
            </summary>
            <exception cref="T:System.InvalidOperationException">Thrown when the operation has not completed yet.</exception>
            <exception cref="T:Azure.RequestFailedException">Thrown when the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletionAsync(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatusAsync(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the parameter <paramref name="pollingInterval" />, but it can change based on information returned
            from the server. After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed. In this case, the maximum value between the <paramref name="pollingInterval" />
            parameter and the retry-after header is chosen as the wait interval. Headers supported are: "Retry-After", "retry-after-ms",
            and "x-ms-retry-after-ms".
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(TimeSpan pollingInterval, CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(pollingInterval, cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletion(System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes.
            After each service call, a retry-after header may be returned to communicate that there is no reason to poll
            for status change until the specified time has passed.
            Headers supported are: "Retry-After", "retry-after-ms", and "x-ms-retry-after-ms",
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="M:Azure.Core.OperationInternal`1.WaitForCompletion(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls <see cref="M:Azure.Core.OperationInternalBase.UpdateStatus(System.Threading.CancellationToken)" /> until the long-running operation completes. The interval
            between calls is defined by the <see cref="T:Azure.Core.FixedDelayWithNoJitterStrategy" />, which takes into account any retry-after header that is returned
            from the server.
            <example>Usage example:
            <code>
              public async ValueTask&lt;Response&lt;T&gt;&gt; WaitForCompletionAsync(CancellationToken cancellationToken) =&gt;
                await _operationInternal.WaitForCompletionAsync(cancellationToken).ConfigureAwait(false);
            </code>
            </example>
            </summary>
            <param name="pollingInterval">The interval between status requests to the server.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>The last HTTP response received from the server, including the final result of the long-running operation.</returns>
            <exception cref="T:Azure.RequestFailedException">Thrown if there's been any issues during the connection, or if the operation has completed with failures.</exception>
        </member>
        <member name="T:Azure.Core.IOperation`1">
            <summary>
            An interface used by <see cref="T:Azure.Core.OperationInternal`1" /> for making service calls and updating state. It's expected that
            your long-running operation classes implement this interface.
            </summary>
            <typeparam name="T">The final result of the long-running operation. Must match the type used in <see cref="T:Azure.Operation`1" />.</typeparam>
        </member>
        <member name="M:Azure.Core.IOperation`1.UpdateStateAsync(System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Calls the service and updates the state of the long-running operation. Properties directly handled by the
            <see cref="T:Azure.Core.OperationInternal`1" /> class, such as <see cref="P:Azure.Core.OperationInternalBase.RawResponse" /> or
            <see cref="P:Azure.Core.OperationInternal`1.Value" />, don't need to be updated. Operation-specific properties, such
            as "<c>CreateOn</c>" or "<c>LastModified</c>", must be manually updated by the operation implementing this
            method.
            <example>Usage example:
            <code>
              async ValueTask&lt;OperationState&lt;T&gt;&gt; IOperation&lt;T&gt;.UpdateStateAsync(bool async, CancellationToken cancellationToken)<br />
              {<br />
                Response&lt;R&gt; response = async ? &lt;async service call&gt; : &lt;sync service call&gt;;<br />
                if (&lt;operation succeeded&gt;) return OperationState&lt;T&gt;.Success(response.GetRawResponse(), &lt;parse response&gt;);<br />
                if (&lt;operation failed&gt;) return OperationState&lt;T&gt;.Failure(response.GetRawResponse());<br />
                return OperationState&lt;T&gt;.Pending(response.GetRawResponse());<br />
              }
            </code>
            </example>
            </summary>
            <param name="async"><c>true</c> if the call should be executed asynchronously. Otherwise, <c>false</c>.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> controlling the request lifetime.</param>
            <returns>
            A structure indicating the current operation state. The <see cref="T:Azure.Core.OperationState`1" /> structure must be instantiated by one of
            its static methods:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState`1.Success(Azure.Response,`0)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </returns>
        </member>
        <member name="T:Azure.Core.OperationState`1">
            <summary>
            A helper structure passed to <see cref="T:Azure.Core.OperationInternal`1" /> to indicate the current operation state. This structure must be
            instantiated by one of its static methods, depending on the operation state:
            <list type="bullet">
              <item>Use <see cref="M:Azure.Core.OperationState`1.Success(Azure.Response,`0)" /> when the operation has completed successfully.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Failure(Azure.Response,Azure.RequestFailedException)" /> when the operation has completed with failures.</item>
              <item>Use <see cref="M:Azure.Core.OperationState`1.Pending(Azure.Response)" /> when the operation has not completed yet.</item>
            </list>
            </summary>
            <typeparam name="T">The final result of the long-running operation. Must match the type used in <see cref="T:Azure.Operation`1" />.</typeparam>
        </member>
        <member name="M:Azure.Core.OperationState`1.Success(Azure.Response,`0)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState`1" /> indicating the operation has completed successfully.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <param name="value">The final result of the long-running operation.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState`1" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> or <paramref name="value" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState`1.Failure(Azure.Response,Azure.RequestFailedException)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState`1" /> indicating the operation has completed with failures.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <param name="operationFailedException">
            The exception to throw from <c>UpdateStatus</c> because of the operation failure. The same exception will be thrown when
            <see cref="P:Azure.Core.OperationInternal`1.Value" /> is called. If left <c>null</c>, a default exception is created based on the
            <paramref name="rawResponse" /> parameter.
            </param>
            <returns>A new <see cref="T:Azure.Core.OperationState`1" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="M:Azure.Core.OperationState`1.Pending(Azure.Response)">
            <summary>
            Instantiates an <see cref="T:Azure.Core.OperationState`1" /> indicating the operation has not completed yet.
            </summary>
            <param name="rawResponse">The HTTP response obtained during the status update.</param>
            <returns>A new <see cref="T:Azure.Core.OperationState`1" /> instance.</returns>
            <exception cref="T:System.ArgumentNullException">Thrown if <paramref name="rawResponse" /> is <c>null</c>.</exception>
        </member>
        <member name="T:Azure.Core.OperationPoller">
            <summary>
            Implementation of LRO polling logic.
            </summary>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.Id">
            <summary>
            Gets an ID representing the operation that can be used to poll for
            the status of the long-running operation.
            There are cases that operation id is not available, we return "NOT_SET" for unavailable operation id.
            </summary>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.Value">
            <summary>
            Final result of the long-running operation.
            </summary><remarks>
            This property can be accessed only after the operation completes successfully (HasValue is true).
            </remarks>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.HasCompleted">
            <summary>
            Returns true if the long-running operation completed.
            </summary>
        </member>
        <member name="P:Azure.Core.ProtocolOperation`1.HasValue">
            <summary>
            Returns true if the long-running operation completed successfully and has produced final result (accessible by Value property).
            </summary>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.GetRawResponse">
            <summary>
            The last HTTP response received from the server.
            </summary><remarks>
            The last response returned from the server during the lifecycle of this instance.
            An instance of <see cref="T:Azure.Operation`1" /> sends requests to a server in UpdateStatusAsync, UpdateStatus, and other methods.
            Responses from these requests can be accessed using GetRawResponse.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.UpdateStatus(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get updated status of the long-running operation.
            </summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the service call.</param><returns>The HTTP response received from the server.</returns><remarks>
            This operation will update the value returned from GetRawResponse and might update HasCompleted.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.UpdateStatusAsync(System.Threading.CancellationToken)">
            <summary>
            Calls the server to get updated status of the long-running operation.
            </summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the service call.</param><returns>The HTTP response received from the server.</returns><remarks>
            This operation will update the value returned from GetRawResponse and might update HasCompleted.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.WaitForCompletionAsync(System.Threading.CancellationToken)">
            <summary>
            Periodically calls the server till the long-running operation completes.
            </summary><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the periodical service calls.</param><returns>The last HTTP response received from the server.</returns><remarks>
            This method will periodically call UpdateStatusAsync till HasCompleted is true, then return the final result of the operation.
            </remarks>
        </member>
        <member name="M:Azure.Core.ProtocolOperation`1.WaitForCompletionAsync(System.TimeSpan,System.Threading.CancellationToken)">
            <summary>
            Periodically calls the server till the long-running operation completes.
            </summary><param name="pollingInterval">
            The interval between status requests to the server.
            The interval can change based on information returned from the server.
            For example, the server might communicate to the client that there is not reason to poll for status change sooner than some time.
            </param><param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken" /> used for the periodical service calls.</param><returns>The last HTTP response received from the server.</returns><remarks>
            This method will periodically call UpdateStatusAsync till HasCompleted is true, then return the final result of the operation.
            </remarks>
        </member>
        <member name="T:Azure.Core.SequentialDelayStrategy">
            <summary>
            A delay strategy that uses a fixed sequence of delays with no jitter applied. This is used by management LROs.
            </summary>
        </member>
        <member name="T:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions">
            <summary> Extension methods to add <see cref="T:Azure.AI.Vision.Face.FaceClient" />, <see cref="T:Azure.AI.Vision.Face.FaceSessionClient" /> to client builder. </summary>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions.AddFaceClient``1(``0,System.Uri,Azure.AzureKeyCredential)">
            <summary> Registers a <see cref="T:Azure.AI.Vision.Face.FaceClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions.AddFaceClient``1(``0,System.Uri)">
            <summary> Registers a <see cref="T:Azure.AI.Vision.Face.FaceClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions.AddFaceSessionClient``1(``0,System.Uri,Azure.AzureKeyCredential)">
            <summary> Registers a <see cref="T:Azure.AI.Vision.Face.FaceSessionClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
            <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions.AddFaceSessionClient``1(``0,System.Uri)">
            <summary> Registers a <see cref="T:Azure.AI.Vision.Face.FaceSessionClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="endpoint">
            Supported Cognitive Services endpoints (protocol and hostname, for example:
            https://{resource-name}.cognitiveservices.azure.com).
            </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions.AddFaceClient``2(``0,``1)">
            <summary> Registers a <see cref="T:Azure.AI.Vision.Face.FaceClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="configuration"> The configuration values. </param>
        </member>
        <member name="M:Microsoft.Extensions.Azure.AIVisionFaceClientBuilderExtensions.AddFaceSessionClient``2(``0,``1)">
            <summary> Registers a <see cref="T:Azure.AI.Vision.Face.FaceSessionClient" /> instance. </summary>
            <param name="builder"> The builder to register with. </param>
            <param name="configuration"> The configuration values. </param>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute">
            <summary>
            Indicates that the specified method requires the ability to generate new code at runtime,
            for example through <see cref="N:System.Reflection" />.
            </summary>
            <remarks>
            This allows tools to understand which methods are unsafe to call when compiling ahead of time.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute" /> class
            with the specified message.
            </summary>
            <param name="message">
            A message that contains information about the usage of dynamic code.
            </param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute.Message">
            <summary>
            Gets a message that contains information about the usage of dynamic code.
            </summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresDynamicCodeAttribute.Url">
            <summary>
            Gets or sets an optional URL that contains more information about the method,
            why it requires dynamic code, and what options a consumer has to deal with it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute">
            <summary>
            Indicates that the specified method requires dynamic access to code that is not referenced
            statically, for example through <see cref="N:System.Reflection" />.
            </summary>
            <remarks>
            This allows tools to understand which methods are unsafe to call when removing unreferenced
            code from an application.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute" /> class
            with the specified message.
            </summary>
            <param name="message">
            A message that contains information about the usage of unreferenced code.
            </param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute.Message">
            <summary>
            Gets a message that contains information about the usage of unreferenced code.
            </summary>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.RequiresUnreferencedCodeAttribute.Url">
            <summary>
            Gets or sets an optional URL that contains more information about the method,
            why it requires unreferenced code, and what options a consumer has to deal with it.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute">
            <summary>
            Suppresses reporting of a specific rule violation, allowing multiple suppressions on a
            single code artifact.
            </summary>
            <remarks>
            <see cref="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute" /> is different than
            <see cref="T:System.Diagnostics.CodeAnalysis.SuppressMessageAttribute" /> in that it doesn't have a
            <see cref="T:System.Diagnostics.ConditionalAttribute" />. So it is always preserved in the compiled assembly.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.#ctor(System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute" />
            class, specifying the category of the tool and the identifier for an analysis rule.
            </summary>
            <param name="category">The category for the attribute.</param>
            <param name="checkId">The identifier of the analysis rule the attribute applies to.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Category">
            <summary>
            Gets the category identifying the classification of the attribute.
            </summary>
            <remarks>
            The <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Category" /> property describes the tool or tool analysis category
            for which a message suppression attribute applies.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.CheckId">
            <summary>
            Gets the identifier of the analysis tool rule to be suppressed.
            </summary>
            <remarks>
            Concatenated together, the <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Category" /> and <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.CheckId" />
            properties form a unique check identifier.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Scope">
            <summary>
            Gets or sets the scope of the code that is relevant for the attribute.
            </summary>
            <remarks>
            The Scope property is an optional argument that specifies the metadata scope for which
            the attribute is relevant.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Target">
            <summary>
            Gets or sets a fully qualified path that represents the target of the attribute.
            </summary>
            <remarks>
            The <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Target" /> property is an optional argument identifying the analysis target
            of the attribute. An example value is "System.IO.Stream.ctor():System.Void".
            Because it is fully qualified, it can be long, particularly for targets such as parameters.
            The analysis tool user interface should be capable of automatically formatting the parameter.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.MessageId">
            <summary>
            Gets or sets an optional argument expanding on exclusion criteria.
            </summary>
            <remarks>
            The <see cref="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.MessageId" /> property is an optional argument that specifies additional
            exclusion where the literal metadata target is not sufficiently precise. For example,
            the <see cref="T:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute" /> cannot be applied within a method,
            and it may be desirable to suppress a violation against a statement in the method that will
            give a rule violation, but not against all statements in the method.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.UnconditionalSuppressMessageAttribute.Justification">
            <summary>
            Gets or sets the justification for suppressing the code analysis message.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute">
            <summary>
            States a dependency that one member has on another.
            </summary>
            <remarks>
            This can be used to inform tooling of a dependency that is otherwise not evident purely from
            metadata and IL, for example a member relied on via reflection.
            </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified signature of a member on the same type as the consumer.
            </summary>
            <param name="memberSignature">The signature of the member depended on.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.String,System.Type)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified signature of a member on a <see cref="T:System.Type" />.
            </summary>
            <param name="memberSignature">The signature of the member depended on.</param>
            <param name="type">The <see cref="T:System.Type" /> containing <paramref name="memberSignature" />.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.String,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified signature of a member on a type in an assembly.
            </summary>
            <param name="memberSignature">The signature of the member depended on.</param>
            <param name="typeName">The full name of the type containing the specified member.</param>
            <param name="assemblyName">The assembly name of the type containing the specified member.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes,System.Type)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified types of members on a <see cref="T:System.Type" />.
            </summary>
            <param name="memberTypes">The types of members depended on.</param>
            <param name="type">The <see cref="T:System.Type" /> containing the specified members.</param>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.#ctor(System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute" /> class
            with the specified types of members on a type in an assembly.
            </summary>
            <param name="memberTypes">The types of members depended on.</param>
            <param name="typeName">The full name of the type containing the specified members.</param>
            <param name="assemblyName">The assembly name of the type containing the specified members.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberSignature">
            <summary>
            Gets the signature of the member depended on.
            </summary>
            <remarks>
            Either <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberSignature" /> must be a valid string or <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberTypes" />
            must not equal <see cref="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.None" />, but not both.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberTypes">
            <summary>
            Gets the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes" /> which specifies the type
            of members depended on.
            </summary>
            <remarks>
            Either <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberSignature" /> must be a valid string or <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.MemberTypes" />
            must not equal <see cref="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.None" />, but not both.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Type">
            <summary>
            Gets the <see cref="T:System.Type" /> containing the specified member.
            </summary>
            <remarks>
            If neither <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Type" /> nor <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName" /> are specified,
            the type of the consumer is assumed.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName">
            <summary>
            Gets the full name of the type containing the specified member.
            </summary>
            <remarks>
            If neither <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Type" /> nor <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName" /> are specified,
            the type of the consumer is assumed.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.AssemblyName">
            <summary>
            Gets the assembly name of the specified type.
            </summary>
            <remarks>
            <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.AssemblyName" /> is only valid when <see cref="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.TypeName" /> is specified.
            </remarks>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicDependencyAttribute.Condition">
            <summary>
            Gets or sets the condition in which the dependency is applicable, e.g. "DEBUG".
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute">
             <summary>
             Indicates that certain members on a specified <see cref="T:System.Type" /> are accessed dynamically,
             for example through <see cref="N:System.Reflection" />.
             </summary>
             <remarks>
             This allows tools to understand which members are being accessed during the execution
             of a program.
            
             This attribute is valid on members whose type is <see cref="T:System.Type" /> or <see cref="T:System.String" />.
            
             When this attribute is applied to a location of type <see cref="T:System.String" />, the assumption is
             that the string represents a fully qualified type name.
            
             When this attribute is applied to a class, interface, or struct, the members specified
             can be accessed dynamically on <see cref="T:System.Type" /> instances returned from calling
             <see cref="M:System.Object.GetType" /> on instances of that class, interface, or struct.
            
             If the attribute is applied to a method it's treated as a special case and it implies
             the attribute should be applied to the "this" parameter of the method. As such the attribute
             should only be used on instance methods of types assignable to System.Type (or string, but no methods
             will use it there).
             </remarks>
        </member>
        <member name="M:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute.#ctor(System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes)">
            <summary>
            Initializes a new instance of the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute" /> class
            with the specified member types.
            </summary>
            <param name="memberTypes">The types of members dynamically accessed.</param>
        </member>
        <member name="P:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMembersAttribute.MemberTypes">
            <summary>
            Gets the <see cref="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes" /> which specifies the type
            of members dynamically accessed.
            </summary>
        </member>
        <member name="T:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes">
             <summary>
             Specifies the types of members that are dynamically accessed.
            
             This enumeration has a <see cref="T:System.FlagsAttribute" /> attribute that allows a
             bitwise combination of its member values.
             </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.None">
            <summary>
            Specifies no members.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicParameterlessConstructor">
            <summary>
            Specifies the default, parameterless public constructor.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicConstructors">
            <summary>
            Specifies all public constructors.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicConstructors">
            <summary>
            Specifies all non-public constructors.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicMethods">
            <summary>
            Specifies all public methods.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicMethods">
            <summary>
            Specifies all non-public methods.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicFields">
            <summary>
            Specifies all public fields.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicFields">
            <summary>
            Specifies all non-public fields.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicNestedTypes">
            <summary>
            Specifies all public nested types.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicNestedTypes">
            <summary>
            Specifies all non-public nested types.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicProperties">
            <summary>
            Specifies all public properties.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicProperties">
            <summary>
            Specifies all non-public properties.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.PublicEvents">
            <summary>
            Specifies all public events.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.NonPublicEvents">
            <summary>
            Specifies all non-public events.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.Interfaces">
            <summary>
            Specifies all interfaces implemented by the type.
            </summary>
        </member>
        <member name="F:System.Diagnostics.CodeAnalysis.DynamicallyAccessedMemberTypes.All">
            <summary>
            Specifies all members.
            </summary>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#AccessoryItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#AccessoryItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AccessoryItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AccessoryItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AccessoryItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AccessoryItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#AuditLivenessResponseInfo}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#AuditLivenessResponseInfo}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AuditLivenessResponseInfo}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AuditLivenessResponseInfo}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditLivenessResponseInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AuditLivenessResponseInfo}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#AuditRequestInfo}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#AuditRequestInfo}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AuditRequestInfo}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AuditRequestInfo}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.AuditRequestInfo.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#AuditRequestInfo}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#BlurProperties}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#BlurProperties}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#BlurProperties}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#BlurProperties}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.BlurProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#BlurProperties}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessSessionContent}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessSessionContent}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessSessionContent}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessSessionContent}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionContent.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessSessionContent}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessSessionResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessSessionResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessSessionResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessSessionResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessSessionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessSessionResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionContent}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionContent}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionContent}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionContent}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionContent.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionContent}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.CreateLivenessWithVerifySessionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#CreateLivenessWithVerifySessionResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#DetectFromUrlRequest}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#DetectFromUrlRequest}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#DetectFromUrlRequest}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#DetectFromUrlRequest}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.DetectFromUrlRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#DetectFromUrlRequest}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#ExposureProperties}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#ExposureProperties}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#ExposureProperties}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#ExposureProperties}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.ExposureProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#ExposureProperties}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceAttributes}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceAttributes}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceAttributes}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceAttributes}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceAttributes.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceAttributes}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceDetectionResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceDetectionResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceDetectionResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceDetectionResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceDetectionResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceDetectionResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceFindSimilarResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceFindSimilarResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceFindSimilarResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceFindSimilarResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceFindSimilarResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceFindSimilarResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceGroupingResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceGroupingResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceGroupingResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceGroupingResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceGroupingResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceGroupingResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceLandmarks}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceLandmarks}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceLandmarks}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceLandmarks}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceLandmarks.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceLandmarks}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceRectangle}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceRectangle}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceRectangle}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceRectangle}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceRectangle.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceRectangle}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceVerificationResult}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FaceVerificationResult}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceVerificationResult}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceVerificationResult}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FaceVerificationResult.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FaceVerificationResult}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FacialHair}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FacialHair}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FacialHair}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FacialHair}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FacialHair.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FacialHair}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FindSimilarRequest}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#FindSimilarRequest}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FindSimilarRequest}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FindSimilarRequest}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.FindSimilarRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#FindSimilarRequest}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#GroupRequest}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#GroupRequest}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#GroupRequest}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#GroupRequest}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.GroupRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#GroupRequest}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#HairColor}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#HairColor}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HairColor}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HairColor}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairColor.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HairColor}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#HairProperties}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#HairProperties}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HairProperties}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HairProperties}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HairProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HairProperties}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#HeadPose}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#HeadPose}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HeadPose}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HeadPose}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.HeadPose.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#HeadPose}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="P:Azure.AI.Vision.Face.ChangeTrackingDictionary`2.System#Collections#Generic#IReadOnlyDictionary{TKey@TValue}#Keys">
            <summary>Gets an enumerable collection that contains the keys in the read-only dictionary.</summary><returns>An enumerable collection that contains the keys in the read-only dictionary.</returns>
        </member>
        <member name="P:Azure.AI.Vision.Face.ChangeTrackingDictionary`2.System#Collections#Generic#IReadOnlyDictionary{TKey@TValue}#Values">
            <summary>Gets an enumerable collection that contains the values in the read-only dictionary.</summary><returns>An enumerable collection that contains the values in the read-only dictionary.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.ChangeTrackingDictionary`2.System#Collections#IEnumerable#GetEnumerator">
            <summary>Returns an enumerator that iterates through a collection.</summary><returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.ChangeTrackingList`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>Returns an enumerator that iterates through a collection.</summary><returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LandmarkCoordinate}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LandmarkCoordinate}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LandmarkCoordinate}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LandmarkCoordinate}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LandmarkCoordinate.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LandmarkCoordinate}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessOutputsTarget}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessOutputsTarget}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessOutputsTarget}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessOutputsTarget}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessOutputsTarget.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessOutputsTarget}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessResponseBody}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessResponseBody}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessResponseBody}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessResponseBody}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessResponseBody.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessResponseBody}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessSession}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessSession}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSession}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSession}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSession.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSession}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessSessionAuditEntry}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessSessionAuditEntry}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSessionAuditEntry}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSessionAuditEntry}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionAuditEntry.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSessionAuditEntry}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessSessionItem}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessSessionItem}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSessionItem}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSessionItem}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessSessionItem.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessSessionItem}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessWithVerifyImage}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessWithVerifyImage}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifyImage}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifyImage}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyImage.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifyImage}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessWithVerifyOutputs}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessWithVerifyOutputs}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifyOutputs}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifyOutputs}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifyOutputs.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifyOutputs}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessWithVerifySession}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#LivenessWithVerifySession}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifySession}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifySession}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.LivenessWithVerifySession.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#LivenessWithVerifySession}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#MaskProperties}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#MaskProperties}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#MaskProperties}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#MaskProperties}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.MaskProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#MaskProperties}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#NoiseProperties}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#NoiseProperties}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#NoiseProperties}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#NoiseProperties}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.NoiseProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#NoiseProperties}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#OcclusionProperties}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#OcclusionProperties}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#OcclusionProperties}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#OcclusionProperties}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.OcclusionProperties.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#OcclusionProperties}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#VerifyFaceToFaceRequest}#Write(System.Text.Json.Utf8JsonWriter,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model to the provided <see cref="T:System.Text.Json.Utf8JsonWriter" />.
            </summary><param name="writer">The <see cref="T:System.Text.Json.Utf8JsonWriter" /> to write into.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.System#ClientModel#Primitives#IJsonModel{Azure#AI#Vision#Face#VerifyFaceToFaceRequest}#Create(System.Text.Json.Utf8JsonReader@,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Reads one JSON value (including objects or arrays) from the provided reader and converts it to a model.
            </summary><param name="reader">The <see cref="T:System.Text.Json.Utf8JsonReader" /> to read.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the JSON value.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#VerifyFaceToFaceRequest}#Write(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Writes the model into a <see cref="T:System.BinaryData" />.
            </summary><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A binary representation of the written model.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#VerifyFaceToFaceRequest}#Create(System.BinaryData,System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Converts the provided <see cref="T:System.BinaryData" /> into a model.
            </summary><param name="data">The <see cref="T:System.BinaryData" /> to parse.</param><param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param><returns>A <typeparamref name="T" /> representation of the data.</returns><exception cref="T:System.FormatException">If the model does not support the requested <see cref="P:System.ClientModel.Primitives.ModelReaderWriterOptions.Format" />.</exception>
        </member>
        <member name="M:Azure.AI.Vision.Face.VerifyFaceToFaceRequest.System#ClientModel#Primitives#IPersistableModel{Azure#AI#Vision#Face#VerifyFaceToFaceRequest}#GetFormatFromOptions(System.ClientModel.Primitives.ModelReaderWriterOptions)">
            <summary>
            Gets the data interchange format (JSON, Xml, etc) that the model uses when communicating with the service.
            <param name="options">The <see cref="T:System.ClientModel.Primitives.ModelReaderWriterOptions" /> to use.</param></summary><returns>The format that the model uses when communicating with the serivce.</returns>
        </member>
        <member name="M:Azure.Core.Pipeline.TaskExtensions.Enumerable`1.System#Collections#Generic#IEnumerable{T}#GetEnumerator">
            <summary>Returns an enumerator that iterates through the collection.</summary><returns>An enumerator that can be used to iterate through the collection.</returns>
        </member>
        <member name="M:Azure.Core.Pipeline.TaskExtensions.Enumerable`1.System#Collections#IEnumerable#GetEnumerator">
            <summary>Returns an enumerator that iterates through a collection.</summary><returns>An <see cref="T:System.Collections.IEnumerator" /> object that can be used to iterate through the collection.</returns>
        </member>
        <member name="P:Azure.Core.Pipeline.TaskExtensions.Enumerator`1.System#Collections#IEnumerator#Current">
            <summary>Gets the element in the collection at the current position of the enumerator.</summary><returns>The element in the collection at the current position of the enumerator.</returns>
        </member>
    </members>
</doc>
